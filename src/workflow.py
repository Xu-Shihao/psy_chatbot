"""
å·¥ä½œæµç®¡ç†æ¨¡å—
æ•´åˆäº†æ‰€æœ‰å·¥ä½œæµç›¸å…³çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- LangGraphå·¥ä½œæµæ„å»º
- å¯¹è¯æ¨¡å¼æ£€æµ‹å’Œå¤„ç†
- é—®è¯Šæµç¨‹ç®¡ç†
- CBTç–—æ„ˆå¸ˆå“åº”
- ç´§æ€¥æƒ…å†µå¤„ç†
- å“åº”ç”Ÿæˆ
"""

import json
import re
from typing import Dict, List, Tuple, Optional
from datetime import datetime
from langchain.schema import HumanMessage, SystemMessage, AIMessage
from langgraph.graph import StateGraph, END

from agent import InterviewState
from prompts import PromptTemplates, KeywordLibrary
from scid5_knowledge import scid5_kb


# =========================
# å·¥ä½œæµæ„å»ºå™¨
# =========================

class WorkflowBuilder:
    """å·¥ä½œæµæ„å»ºå™¨"""
    
    def __init__(self, agent):
        self.agent = agent
    
    def create_workflow(self) -> StateGraph:
        """åˆ›å»ºé—®è¯Šå·¥ä½œæµ"""
        workflow = StateGraph(InterviewState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("start_interview", self.agent.start_interview)
        workflow.add_node("detect_conversation_mode", self.agent.detect_conversation_mode)
        workflow.add_node("chat_therapist_response", self.agent.chat_therapist_response)
        workflow.add_node("understand_and_respond", self.agent.understand_and_respond)
        workflow.add_node("ask_question", self.agent.ask_question)
        workflow.add_node("check_emergency", self.agent.check_emergency)
        workflow.add_node("generate_summary", self.agent.generate_summary)
        workflow.add_node("emergency_response", self.agent.emergency_response)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("start_interview")
        
        # å®šä¹‰è¾¹
        workflow.add_edge("start_interview", "detect_conversation_mode")
        workflow.add_conditional_edges(
            "detect_conversation_mode",
            self.should_continue_after_mode_detection,
            {
                "interview": "understand_and_respond",  # ç›´æ¥è¿›å…¥ç†è§£å’Œå›åº”é˜¶æ®µ
                "chat": "chat_therapist_response",
                "assessment_complete": "chat_therapist_response"
            }
        )
        workflow.add_edge("chat_therapist_response", END)
        workflow.add_conditional_edges(
            "understand_and_respond",
            self.should_continue_after_understand_and_respond,
            {
                "continue": "check_emergency",
                "emergency": "emergency_response",
                "complete": "generate_summary",
                "wait_response": END
            }
        )
        workflow.add_conditional_edges(
            "check_emergency",
            self.should_continue_after_check,
            {
                "continue": "detect_conversation_mode",
                "complete": "generate_summary",
                "emergency": "emergency_response"
            }
        )
        workflow.add_edge("generate_summary", END)
        workflow.add_edge("emergency_response", END)
        
        return workflow
    
    def should_continue_after_mode_detection(self, state: InterviewState) -> str:
        """å†³å®šæ¨¡å¼æ£€æµ‹åçš„ä¸‹ä¸€æ­¥"""
        # å¦‚æœæ˜¯ç»“æ„åŒ–æ¨¡å¼ä¸”æœªå®Œæˆè¯„ä¼°ï¼Œå¼ºåˆ¶è¿›å…¥é—®è¯Šæµç¨‹
        if (self.agent.workflow_mode == "structured" and 
            not state.get("assessment_complete", False)):
            print(f"ğŸ”’ å·¥ä½œæµå¼ºåˆ¶è·¯ç”±åˆ°é—®è¯Šæ¨¡å¼ - ç»“æ„åŒ–æ¨¡å¼æœªå®Œæˆè¯„ä¼°")
            return "interview"
        
        # æ™ºèƒ½æ£€æµ‹æ¨¡å¼çš„åŸæœ‰é€»è¾‘
        mode = state.get("conversation_mode", "interview")
        
        if mode == "chat":
            return "chat"
        elif mode in ["interview", "continue_interview"]:
            return "interview"  # ç»Ÿä¸€æ˜ å°„åˆ°interviewæµç¨‹
        elif mode == "assessment_complete":
            return "assessment_complete"  
        else:
            return "interview"  # é»˜è®¤è¿›å…¥é—®è¯Šæ¨¡å¼
    
    def should_continue_after_understand_and_respond(self, state: InterviewState) -> str:
        """ç†è§£å’Œå›åº”åçš„æµç¨‹æ§åˆ¶"""
        if state["emergency_situation"]:
            return "emergency"
        elif state["assessment_complete"]:
            return "complete"
        else:
            return "continue"
    
    def should_continue_after_question(self, state: InterviewState) -> str:
        """é—®é¢˜åçš„æµç¨‹æ§åˆ¶ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰"""
        if state["emergency_situation"]:
            return "emergency"
        return "wait_response"
    
    def should_continue_after_check(self, state: InterviewState) -> str:
        """æ£€æŸ¥åçš„æµç¨‹æ§åˆ¶"""
        if state["emergency_situation"]:
            return "emergency"
        elif state["assessment_complete"]:
            return "complete"
        else:
            # è·å–ä¸‹ä¸€ä¸ªé—®é¢˜
            current_question_id = state["current_question_id"]
            last_response = ""
            for msg in reversed(state["messages"]):
                if hasattr(msg, 'content'):
                    last_response = msg.content
                    break
            
            if current_question_id and last_response:
                next_question = scid5_kb.get_next_question(current_question_id, last_response)
                if next_question:
                    # æ›´æ–°åˆ°ä¸‹ä¸€ä¸ªé—®é¢˜
                    state["current_question_id"] = next_question.id
                    return "continue"
                else:
                    state["assessment_complete"] = True
                    return "complete"
            
            return "complete"


# =========================
# å¢å¼ºæ„å›¾æ£€æµ‹å™¨
# =========================

class EnhancedIntentDetector:
    """å¢å¼ºçš„æ„å›¾æ£€æµ‹å™¨"""
    
    def __init__(self, llm, workflow_mode: str = "adaptive"):
        self.llm = llm
        self.workflow_mode = workflow_mode
    
    def detect_conversation_mode(self, state: InterviewState) -> InterviewState:
        """å¢å¼ºçš„å¯¹è¯æ¨¡å¼æ£€æµ‹"""
        
        # 1. æ£€æŸ¥åŸºæœ¬çŠ¶æ€
        if state.get("assessment_complete", False):
            return self._handle_assessment_complete(state)
        
        # 2. æ£€æŸ¥ç´§æ€¥æƒ…å†µ
        emergency_result = self._check_emergency_priority(state)
        if emergency_result["is_emergency"]:
            return self._handle_emergency_mode(state, emergency_result)
        
        # 3. è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯
        context = self._extract_conversation_context(state)
        
        # 4. ç»“æ„åŒ–æ¨¡å¼å¤„ç†
        if self.workflow_mode == "structured":
            return self._handle_structured_mode(state, context)
        
        # 5. æ™ºèƒ½æ£€æµ‹æ¨¡å¼
        return self._handle_adaptive_mode(state, context)
    
    def _extract_conversation_context(self, state: InterviewState) -> Dict:
        """æå–å¯¹è¯ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        user_messages = [msg for msg in state["messages"] if isinstance(msg, HumanMessage)]
        ai_messages = [msg for msg in state["messages"] if isinstance(msg, AIMessage)]
        
        if not user_messages:
            return {
                "current_turn": 0,
                "latest_message": "",
                "message_length": 0,
                "conversation_history": [],
                "emotional_state": "neutral",
                "symptom_severity": "none",
                "user_engagement": "unknown"
            }
        
        latest_message = user_messages[-1].content
        current_turn = state.get("conversation_turn_count", 0)
        
        # åˆ†ææƒ…ç»ªçŠ¶æ€
        emotional_state = self._detect_emotional_state(latest_message)
        
        # åˆ†æç—‡çŠ¶ä¸¥é‡ç¨‹åº¦
        symptom_severity = self._assess_symptom_severity(latest_message)
        
        # è¯„ä¼°ç”¨æˆ·å‚ä¸åº¦
        user_engagement = self._assess_user_engagement(state, latest_message)
        
        # åˆ†ææ¶ˆæ¯å¤æ‚åº¦
        message_complexity = self._analyze_message_complexity(latest_message)
        
        return {
            "current_turn": current_turn,
            "latest_message": latest_message,
            "message_length": len(latest_message),
            "conversation_history": [msg.content for msg in user_messages[-3:]],  # æœ€è¿‘3æ¡
            "emotional_state": emotional_state,
            "symptom_severity": symptom_severity,
            "user_engagement": user_engagement,
            "message_complexity": message_complexity,
            "response_pattern": self._analyze_response_pattern(state)
        }
    
    def _detect_emotional_state(self, message: str) -> str:
        """æ£€æµ‹ç”¨æˆ·çš„æƒ…ç»ªçŠ¶æ€"""
        for emotion, keywords in KeywordLibrary.EMOTION_PATTERNS.items():
            if any(keyword in message for keyword in keywords):
                return emotion
        return "neutral"
    
    def _assess_symptom_severity(self, message: str) -> str:
        """è¯„ä¼°ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦"""
        for severity, keywords in KeywordLibrary.SYMPTOM_KEYWORDS.items():
            if any(keyword in message for keyword in keywords):
                return severity.replace("_severity", "")
        return "none"
    
    def _assess_user_engagement(self, state: InterviewState, latest_message: str) -> str:
        """è¯„ä¼°ç”¨æˆ·å‚ä¸åº¦"""
        # åŸºäºæ¶ˆæ¯é•¿åº¦ã€å›å¤é€Ÿåº¦ã€å†…å®¹è¯¦ç»†ç¨‹åº¦è¯„ä¼°
        message_length = len(latest_message)
        
        if message_length < 5:
            return "low"
        elif message_length < 20:
            return "medium"
        else:
            return "high"
    
    def _analyze_message_complexity(self, message: str) -> Dict:
        """åˆ†ææ¶ˆæ¯å¤æ‚åº¦"""
        return {
            "length": len(message),
            "word_count": len(message.split()),
            "sentence_count": len([s for s in message.split('ã€‚') if s.strip()]),
            "question_count": message.count('ï¼Ÿ') + message.count('?'),
            "has_specific_details": len(message) > 30 and ('å› ä¸º' in message or 'æ‰€ä»¥' in message)
        }
    
    def _analyze_response_pattern(self, state: InterviewState) -> str:
        """åˆ†æç”¨æˆ·çš„å›å¤æ¨¡å¼"""
        user_messages = [msg for msg in state["messages"] if isinstance(msg, HumanMessage)]
        
        if len(user_messages) < 2:
            return "initial"
        
        recent_messages = [msg.content for msg in user_messages[-3:]]
        avg_length = sum(len(msg) for msg in recent_messages) / len(recent_messages)
        
        if avg_length < 10:
            return "brief"
        elif avg_length > 50:
            return "detailed"
        else:
            return "moderate"
    
    def _check_emergency_priority(self, state: InterviewState) -> Dict:
        """æ£€æŸ¥æ˜¯å¦æœ‰ç´§æ€¥æƒ…å†µéœ€è¦ä¼˜å…ˆå¤„ç†"""
        user_messages = [msg for msg in state["messages"] if isinstance(msg, HumanMessage)]
        if not user_messages:
            return {"is_emergency": False, "severity": "none"}
        
        latest_message = user_messages[-1].content
        
        # æ£€æŸ¥é«˜é£é™©å…³é”®è¯
        for keyword in KeywordLibrary.SYMPTOM_KEYWORDS["high_severity"]:
            if keyword in latest_message:
                return {
                    "is_emergency": True,
                    "severity": "high",
                    "trigger_keywords": [keyword],
                    "message": latest_message
                }
        
        return {"is_emergency": False, "severity": "none"}
    
    def _handle_emergency_mode(self, state: InterviewState, emergency_result: Dict) -> InterviewState:
        """å¤„ç†ç´§æ€¥æƒ…å†µæ¨¡å¼"""
        return {
            **state,
            "conversation_mode": "emergency",
            "emergency_situation": True,
            "chat_therapist_active": False,
            "interview_mode_locked": True,
            "mode_detection_result": {
                "detected_mode": "emergency",
                "confidence": 1.0,
                "reason": f"æ£€æµ‹åˆ°ç´§æ€¥æƒ…å†µï¼š{emergency_result['trigger_keywords']}",
                "emergency_details": emergency_result
            }
        }
    
    def _handle_assessment_complete(self, state: InterviewState) -> InterviewState:
        """å¤„ç†è¯„ä¼°å®ŒæˆçŠ¶æ€"""
        return {
            **state,
            "conversation_mode": "assessment_complete",
            "chat_therapist_active": True,
            "mode_detection_result": {
                "detected_mode": "assessment_complete",
                "confidence": 1.0,
                "reason": "è¯„ä¼°å·²å®Œæˆï¼Œè¿›å…¥åç»­æ”¯æŒæ€§å¯¹è¯æ¨¡å¼"
            }
        }
    
    def _handle_structured_mode(self, state: InterviewState, context: Dict) -> InterviewState:
        """å¤„ç†ç»“æ„åŒ–æ¨¡å¼"""
        current_turn = context["current_turn"]
        
        # ç»“æ„åŒ–æ¨¡å¼ï¼šå¼ºåˆ¶é—®è¯Šç›´åˆ°å®Œæˆ
        return {
            **state,
            "conversation_mode": "continue_interview",
            "chat_therapist_active": False,
            "conversation_turn_count": current_turn + 1,
            "interview_mode_locked": True,
            "mode_detection_result": {
                "detected_mode": "continue_interview",
                "confidence": 1.0,
                "reason": "ç»“æ„åŒ–æ¨¡å¼ï¼šå¼ºåˆ¶è¿›è¡Œå®Œæ•´é—®è¯Šæµç¨‹",
                "context_analysis": context
            }
        }
    
    def _handle_adaptive_mode(self, state: InterviewState, context: Dict) -> InterviewState:
        """å¤„ç†è‡ªé€‚åº”æ¨¡å¼"""
        current_turn = context["current_turn"]
        latest_message = context["latest_message"]
        emotional_state = context["emotional_state"]
        symptom_severity = context["symptom_severity"]
        user_engagement = context["user_engagement"]
        
        # æ£€æŸ¥æ˜¯å¦å·²é”å®šé—®è¯Šæ¨¡å¼
        if state.get("interview_mode_locked", False):
            return {
                **state,
                "conversation_mode": "continue_interview",
                "chat_therapist_active": False,
                "conversation_turn_count": current_turn + 1,
                "mode_detection_result": {
                    "detected_mode": "continue_interview",
                    "confidence": 1.0,
                    "reason": "é—®è¯Šæ¨¡å¼å·²é”å®šï¼Œç»§ç»­å®Œæˆè¯„ä¼°",
                    "context_analysis": context
                }
            }
        
        # ä½¿ç”¨å¢å¼ºçš„LLMæ£€æµ‹
        detection_result = self._enhanced_llm_detection(state, context)
        
        # åŸºäºå¤šç»´åº¦åˆ†æåšæœ€ç»ˆå†³ç­–
        final_mode = self._make_final_decision(detection_result, context, state)
        
        return final_mode
    
    def _enhanced_llm_detection(self, state: InterviewState, context: Dict) -> Dict:
        """å¢å¼ºçš„LLMæ„å›¾æ£€æµ‹"""
        latest_message = context["latest_message"]
        current_turn = context["current_turn"]
        emotional_state = context["emotional_state"]
        symptom_severity = context["symptom_severity"]
        conversation_history = context["conversation_history"]
        
        # æ„å»ºæ›´æ™ºèƒ½çš„æ£€æµ‹æç¤º
        detection_prompt = PromptTemplates.get_enhanced_intent_detection_prompt(
            latest_message, current_turn, emotional_state, symptom_severity, conversation_history
        )
        
        try:
            print("ğŸ§  å¢å¼ºæ„å›¾æ£€æµ‹ - LLMåˆ†æä¸­...")
            
            detection_response = self.llm.invoke([
                SystemMessage(content=PromptTemplates.INTENT_ANALYST_SYSTEM_PROMPT),
                HumanMessage(content=detection_prompt)
            ])
            
            result = json.loads(detection_response.content)
            print(f"âœ… æ£€æµ‹ç»“æœï¼š{result['primary_intent']} (ç½®ä¿¡åº¦: {result['confidence']})")
            
            return result
            
        except Exception as e:
            print(f"âŒ å¢å¼ºæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨åå¤‡é€»è¾‘: {e}")
            return self._fallback_detection(latest_message, context)
    
    def _fallback_detection(self, message: str, context: Dict) -> Dict:
        """åå¤‡æ£€æµ‹é€»è¾‘"""
        symptom_severity = context["symptom_severity"]
        emotional_state = context["emotional_state"]
        
        # åŸºäºç—‡çŠ¶ä¸¥é‡ç¨‹åº¦å’Œæƒ…ç»ªçŠ¶æ€çš„åå¤‡åˆ¤æ–­
        if symptom_severity in ["high", "medium"]:
            return {
                "primary_intent": "interview",
                "confidence": 0.8,
                "reasoning": f"æ£€æµ‹åˆ°{symptom_severity}çº§åˆ«ç—‡çŠ¶ï¼Œå»ºè®®é—®è¯Šè¯„ä¼°",
                "urgency_level": "high" if symptom_severity == "high" else "medium"
            }
        elif emotional_state in ["distressed", "anxious", "sad"]:
            return {
                "primary_intent": "supportive_chat",
                "confidence": 0.7,
                "reasoning": f"ç”¨æˆ·æƒ…ç»ªçŠ¶æ€ä¸º{emotional_state}ï¼Œéœ€è¦æ”¯æŒæ€§å¯¹è¯",
                "urgency_level": "medium"
            }
        elif any(keyword in message for keyword in KeywordLibrary.CHAT_KEYWORDS):
            return {
                "primary_intent": "chat",
                "confidence": 0.8,
                "reasoning": "ç”¨æˆ·æ˜ç¡®è¡¨è¾¾æƒ³è¦é—²èŠ",
                "urgency_level": "low"
            }
        else:
            return {
                "primary_intent": "continue_interview",
                "confidence": 0.6,
                "reasoning": "é»˜è®¤ç»§ç»­é—®è¯Šæµç¨‹",
                "urgency_level": "low"
            }
    
    def _make_final_decision(self, detection_result: Dict, context: Dict, state: InterviewState) -> InterviewState:
        """åŸºäºå¤šç»´åº¦åˆ†æåšæœ€ç»ˆå†³ç­–"""
        primary_intent = detection_result["primary_intent"]
        confidence = detection_result.get("confidence", 0.5)
        urgency_level = detection_result.get("urgency_level", "low")
        current_turn = context["current_turn"]
        
        # å†³ç­–é€»è¾‘ä¼˜åŒ–
        final_mode = primary_intent
        should_lock = False
        chat_active = False
        
        # é«˜ç½®ä¿¡åº¦ä¸”é«˜ç´§æ€¥åº¦çš„é—®è¯Šéœ€æ±‚ï¼Œç«‹å³é”å®š
        if primary_intent in ["interview", "continue_interview"]:
            if confidence > 0.7 or urgency_level == "high":
                should_lock = True
            chat_active = False
            
        elif primary_intent in ["chat", "supportive_chat"]:
            chat_active = True
            should_lock = False
            
        # å¯¹äºä½ç½®ä¿¡åº¦çš„åˆ¤æ–­ï¼Œé»˜è®¤åˆ‡æ¢åˆ°CBTé—²èŠæ¨¡å¼
        if confidence < 0.6 and current_turn < 3:
            final_mode = "chat"  # æ²¡æœ‰æ˜ç¡®é—®è¯Šæ„å›¾æ—¶ï¼Œé»˜è®¤è¿›å…¥CBTé—²èŠæ¨¡å¼
            chat_active = True
            should_lock = False
            print(f"ğŸ”„ æ„å›¾ä¸æ˜ç¡®ï¼ˆç½®ä¿¡åº¦: {confidence:.2f}ï¼‰ï¼Œåˆ‡æ¢åˆ°CBTé—²èŠæ¨¡å¼", flush=True)
            
        return {
            **state,
            "conversation_mode": final_mode,
            "chat_therapist_active": chat_active,
            "conversation_turn_count": current_turn + 1,
            "interview_mode_locked": should_lock,
            "mode_detection_result": {
                **detection_result,
                "final_decision": final_mode,
                "locked": should_lock,
                "turn_count": current_turn + 1,
                "context_analysis": context
            }
        }
    
    def get_detection_summary(self, state: InterviewState) -> str:
        """è·å–æ£€æµ‹ç»“æœæ‘˜è¦"""
        result = state.get("mode_detection_result", {})
        
        summary = f"""
        ğŸ” æ„å›¾æ£€æµ‹ç»“æœï¼š
        - æ£€æµ‹æ¨¡å¼ï¼š{result.get('detected_mode', 'æœªçŸ¥')}
        - ç½®ä¿¡åº¦ï¼š{result.get('confidence', 0):.2f}
        - åŸå› ï¼š{result.get('reason', 'æ— ')}
        - æƒ…æ„Ÿéœ€æ±‚ï¼š{result.get('emotional_needs', 'æœªåˆ†æ')}
        - ç´§æ€¥ç¨‹åº¦ï¼š{result.get('urgency_level', 'æœªçŸ¥')}
        """
        
        return summary


# =========================
# å¯¹è¯æ¨¡å¼å¤„ç†å™¨
# =========================

class ConversationModeHandler:
    """å¯¹è¯æ¨¡å¼å¤„ç†å™¨ - é›†æˆå¢å¼ºæ„å›¾æ£€æµ‹"""
    
    def __init__(self, llm, workflow_mode: str = "adaptive"):
        self.llm = llm
        self.workflow_mode = workflow_mode
        
        # åˆå§‹åŒ–å¢å¼ºæ„å›¾æ£€æµ‹å™¨
        self.intent_detector = EnhancedIntentDetector(llm, workflow_mode)
        
        # ä¿ç•™åŸæœ‰çš„ç®€å•æ£€æµ‹ä½œä¸ºåå¤‡
        self.simple_detection_enabled = True
    
    def detect_conversation_mode(self, state: InterviewState) -> InterviewState:
        """æ£€æµ‹å¯¹è¯æ¨¡å¼ - ä½¿ç”¨å¢å¼ºæ£€æµ‹å™¨"""
        try:
            # ä½¿ç”¨å¢å¼ºçš„æ„å›¾æ£€æµ‹
            result = self.intent_detector.detect_conversation_mode(state)
            
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            if result.get("mode_detection_result"):
                print("ğŸ” å¢å¼ºæ„å›¾æ£€æµ‹ç»“æœï¼š")
                print(f"  æ¨¡å¼: {result['conversation_mode']}")
                print(f"  ç½®ä¿¡åº¦: {result['mode_detection_result'].get('confidence', 'N/A')}")
                print(f"  åŸå› : {result['mode_detection_result'].get('reason', 'N/A')}")
            
            return result
                
        except Exception as e:
            print(f"âš ï¸ å¢å¼ºæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ£€æµ‹: {e}")
            
            # åå¤‡ï¼šä½¿ç”¨åŸæœ‰çš„ç®€å•æ£€æµ‹é€»è¾‘
            if self.simple_detection_enabled:
                return self._simple_detection_fallback(state)
            else:
                raise e
    
    def _simple_detection_fallback(self, state: InterviewState) -> InterviewState:
        """ç®€å•æ£€æµ‹åå¤‡é€»è¾‘ï¼ˆåŸæœ‰é€»è¾‘çš„ç®€åŒ–ç‰ˆï¼‰"""
        print("ğŸ”„ ä½¿ç”¨ç®€å•æ£€æµ‹åå¤‡é€»è¾‘")
        
        # å¦‚æœå·²ç»å®Œæˆè¯„ä¼°ï¼Œé»˜è®¤è¿›å…¥é—²èŠæ¨¡å¼
        if state.get("assessment_complete", False):
            return {
                **state,
                "conversation_mode": "assessment_complete",
                "chat_therapist_active": True,
                "mode_detection_result": {
                    "detected_mode": "assessment_complete",
                    "confidence": 1.0,
                    "reason": "è¯„ä¼°å·²å®Œæˆï¼Œè¿›å…¥åç»­é—²èŠæ¨¡å¼"
                }
            }
        
        # è·å–å½“å‰ä¼šè¯è½®æ•°
        current_turn = state.get("conversation_turn_count", 0)
        interview_locked = state.get("interview_mode_locked", False)
        
        # å¦‚æœé—®è¯Šæ¨¡å¼å·²é”å®šï¼Œå¼ºåˆ¶ç»§ç»­é—®è¯Š
        if interview_locked:
            return {
                **state,
                "conversation_mode": "continue_interview",
                "chat_therapist_active": False,
                "conversation_turn_count": current_turn + 1,
                "mode_detection_result": {
                    "detected_mode": "continue_interview",
                    "confidence": 1.0,
                    "reason": "é—®è¯Šæ¨¡å¼å·²é”å®šï¼Œç»§ç»­è¿›è¡Œé—®è¯Šç›´è‡³å®Œæˆ"
                }
            }
        
        # ç»“æ„åŒ–æ¨¡å¼ï¼šå¦‚æœè¯„ä¼°æœªå®Œæˆï¼Œå¼ºåˆ¶è¿›å…¥é—®è¯Šæ¨¡å¼
        if (self.workflow_mode == "structured" and 
            not state.get("assessment_complete", False)):
            print(f"ğŸ”’ ç»“æ„åŒ–æ¨¡å¼å¼ºåˆ¶é”å®šé—®è¯Šæµç¨‹ - è¯„ä¼°æœªå®Œæˆ")
            return {
                **state,
                "conversation_mode": "continue_interview",
                "chat_therapist_active": False,
                "conversation_turn_count": current_turn + 1,
                "interview_mode_locked": True,
                "mode_detection_result": {
                    "detected_mode": "continue_interview",
                    "confidence": 1.0,
                    "reason": "ç»“æ„åŒ–æ¨¡å¼ï¼šå¼ºåˆ¶è¿›å…¥é—®è¯Šæµç¨‹å¹¶é”å®š"
                }
            }
        
        # è·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
        user_messages = [msg for msg in state["messages"] if isinstance(msg, HumanMessage)]
        if not user_messages:
            return {
                **state,
                "conversation_mode": "interview",
                "conversation_turn_count": current_turn + 1,
                "mode_detection_result": {
                    "detected_mode": "interview",
                    "confidence": 0.8,
                    "reason": "æ²¡æœ‰ç”¨æˆ·è¾“å…¥ï¼Œé»˜è®¤å¼€å§‹é—®è¯Š"
                }
            }
        
        latest_user_message = user_messages[-1].content
        
        # ç®€å•å…³é”®è¯æ£€æµ‹
        if any(keyword in latest_user_message for keyword in KeywordLibrary.CHAT_KEYWORDS):
            mode = "chat"
            will_lock = False
        elif any(keyword in latest_user_message for keyword in KeywordLibrary.INTERVIEW_KEYWORDS):
            mode = "interview"
            will_lock = True
        else:
            # é»˜è®¤åˆ‡æ¢åˆ°CBTé—²èŠæ¨¡å¼ï¼ˆæ²¡æœ‰æ˜ç¡®é—®è¯Šæ„å›¾æ—¶ï¼‰
            mode = "chat"
            will_lock = False
            print(f"ğŸ”„ ç®€å•æ£€æµ‹ï¼šæ²¡æœ‰æ˜ç¡®æ„å›¾ï¼Œåˆ‡æ¢åˆ°CBTé—²èŠæ¨¡å¼", flush=True)
        
        return {
            **state,
            "conversation_mode": mode,
            "chat_therapist_active": mode == "chat",
            "conversation_turn_count": current_turn + 1,
            "interview_mode_locked": will_lock,
            "mode_detection_result": {
                "detected_mode": mode,
                "confidence": 0.7,
                "reason": "ç®€å•å…³é”®è¯æ£€æµ‹åå¤‡é€»è¾‘",
                "fallback_used": True
            }
        }



# =========================
# é—®è¯Šæµç¨‹å¤„ç†å™¨
# =========================

class InterviewFlowHandler:
    """é—®è¯Šæµç¨‹å¤„ç†å™¨"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def start_interview(self, state: InterviewState) -> InterviewState:
        """å¼€å§‹é—®è¯Š - ç”Ÿæˆè‡ªæˆ‘ä»‹ç»å’Œå¼•å¯¼å¼€åœºç™½"""
        system_message = SystemMessage(content=PromptTemplates.COUNSELOR_SYSTEM_PROMPT)
        
        # ç”Ÿæˆè‡ªæˆ‘ä»‹ç»å’Œå¼•å¯¼å¼€åœºç™½
        try:
            print("=" * 50)
            print("ğŸ” DEBUG - START_INTERVIEW LLM CALL", flush=True)
            print("PROMPT:")
            print(PromptTemplates.INITIAL_INTERVIEW_PROMPT)
            print("=" * 50)
            
            response = self.llm.invoke([HumanMessage(content=PromptTemplates.INITIAL_INTERVIEW_PROMPT)])
            initial_response = response.content.strip()
            
            print("RESPONSE:")
            print(initial_response)
            print("=" * 50)
            
            # æ·»åŠ é‡è¦è¯´æ˜
            initial_response += PromptTemplates.IMPORTANT_DISCLAIMER
            
        except Exception as e:
            print(f"ğŸ” DEBUG: LLMç”Ÿæˆå¼€å¤´å¤±è´¥: {e}", flush=True)
            # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å¼€å¤´
            initial_response = PromptTemplates.FALLBACK_INTERVIEW_INTRO + PromptTemplates.IMPORTANT_DISCLAIMER
        
        # åˆ›å»ºAIæ¶ˆæ¯
        intro_message = AIMessage(content=initial_response)
        
        return {
            **state,
            "messages": [system_message, intro_message],
            "current_question_id": "initial",  # è®¾ç½®ä¸ºåˆå§‹çŠ¶æ€ï¼Œç­‰å¾…ç”¨æˆ·åˆ†äº«ä¸»è¯‰
            "user_responses": {},
            "assessment_complete": False,
            "emergency_situation": False,
            "summary": "",
            "needs_followup": False,
            "conversation_history": [],
            "followup_questions": [],
            "risk_level": "low",
            "risk_indicators": [],
            "emotional_state": "",
            "content_complete": False,
            "understanding_summary": "",
            "empathetic_response": "",
            "current_analysis": {},
            "debug_info": [],
            "session_start_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "question_sequence": ["initial"],
            "final_response": "",
            "assessment_duration": 0,
            "user_engagement_level": "medium",
            "response_detail_level": "moderate",
            "symptoms_identified": [],
            "domains_assessed": ["initial"],
            "severity_indicators": {},
            "chief_complaint": "",
            "conversation_mode": "idle",  # å¼€å§‹æ—¶ä¸ºç©ºé—²æ¨¡å¼ï¼Œç­‰å¾…ç”¨æˆ·æ„å›¾æ£€æµ‹
            "chat_therapist_active": False,
            "mode_detection_result": {},
            "conversation_turn_count": 0,  # åˆå§‹åŒ–ä¼šè¯è½®æ•°
            "interview_mode_locked": False,  # åˆå§‹åŒ–é—®è¯Šæ¨¡å¼é”å®šçŠ¶æ€
            "current_topic": "åˆå§‹åŒ–é—®è¯Š",
            "is_follow_up": False,
            "assessed_criteria": {},  # åˆå§‹åŒ–å·²è¯„ä¼°çš„è¯Šæ–­æ ‡å‡†ï¼ˆåªè®°å½•å·²é—®è¿‡çš„ç—‡çŠ¶ï¼‰
            "current_disorder_focus": "mood_disorders"  # åˆå§‹å…³æ³¨æŠ‘éƒç—‡
        }
    
    def understand_and_respond(self, state: InterviewState) -> InterviewState:
        """ç†è§£ç”¨æˆ·å›ç­”å¹¶æä¾›å…±æƒ…å›åº”ï¼ŒåŒæ—¶æå‡ºä¸‹ä¸€ä¸ªé—®é¢˜"""
        if len(state["messages"]) < 2:
            return state
        
        # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        last_user_message = None
        for msg in reversed(state["messages"]):
            if isinstance(msg, HumanMessage):
                last_user_message = msg.content
                break
        
        if not last_user_message:
            return state
        
        current_question_id = state["current_question_id"]
        current_question = scid5_kb.questions.get(current_question_id) if current_question_id else None
        
        # è·å–å¯¹è¯ä¸Šä¸‹æ–‡
        conversation_context = "\n".join(state["conversation_history"][-10:]) if state["conversation_history"] else ""
        
        # æ„å»ºç»¼åˆåˆ†æå’Œå›åº”çš„æç¤º
        next_question_info = self._get_next_question_info(current_question_id, last_user_message, state)
        
        current_disorder_focus = state.get("current_question_id", "depression_screening")
        
        # è·å–ä¸Šä¸€è½®AIçš„çœŸå®å›å¤ä½œä¸ºä¸Šä¸‹æ–‡
        last_ai_response = ""
        for msg in reversed(state.get("messages", [])):
            if isinstance(msg, AIMessage):
                last_ai_response = msg.content
                break
        
        comprehensive_prompt = PromptTemplates.get_comprehensive_analysis_prompt(
            conversation_context, last_ai_response, last_user_message, 
            current_disorder_focus, next_question_info
        )
        
        print("=" * 50)
        print("ğŸ” DEBUG - UNDERSTAND_AND_RESPOND (COMPREHENSIVE) LLM CALL", flush=True)
        print("PROMPT:")
        print(comprehensive_prompt)
        print("=" * 50)
        
        response = self.llm.invoke([HumanMessage(content=comprehensive_prompt)])
        
        print("RESPONSE:")
        print(response.content)
        print("=" * 50)
        
        try:
            analysis = json.loads(response.content)
        except:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œæä¾›é»˜è®¤å›åº”
            analysis = {
                "emotional_state": "æœªèƒ½è¯†åˆ«",
                "risk_level": "low",
                "risk_indicators": [],
                "understanding_summary": last_user_message,
                "has_next_question": False,
                "next_question_id": None,
                "comprehensive_response": "è°¢è°¢æ‚¨çš„åˆ†äº«ã€‚æˆ‘å¬åˆ°äº†æ‚¨çš„æ„Ÿå—ï¼Œè®©æˆ‘ä»¬ç»§ç»­èŠèŠã€‚",
                "assessment_complete": False
            }
        
        # è®°å½•ç”¨æˆ·å›ç­”
        updated_responses = state["user_responses"].copy()
        if current_question_id:
            updated_responses[current_question_id] = last_user_message
        
        # æ›´æ–°å·²è¯„ä¼°çš„ç—‡çŠ¶æ ‡å‡†
        updated_state_with_criteria = self._update_assessed_criteria(state, current_question_id, last_user_message)
        
        # ç”Ÿæˆå›åº”æ¶ˆæ¯
        ai_response = AIMessage(content=analysis["comprehensive_response"])
        
        # æ›´æ–°å¯¹è¯å†å² - ä½¿ç”¨çœŸå®çš„AIå›å¤å†…å®¹
        updated_history = state["conversation_history"].copy()
        # å¦‚æœæ˜¯ç¬¬ä¸€è½®å¯¹è¯ï¼Œæ·»åŠ ä¸Šä¸€è½®çš„AIå›å¤ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if len(state["messages"]) > 1:
            last_ai_message = None
            for msg in reversed(state["messages"]):
                if isinstance(msg, AIMessage):
                    last_ai_message = msg.content
                    break
            if last_ai_message:
                updated_history.append(f"You: {last_ai_message}")
        updated_history.append(f"User: {last_user_message}")
        # æ³¨æ„ï¼šä¸åœ¨è¿™é‡Œæ·»åŠ å½“å‰AIå›å¤ï¼Œå› ä¸ºå®ƒä¼šåœ¨ä¸‹ä¸€è½®çš„å†å²ä¸­æ˜¾ç¤º
        
        # æ›´æ–°å½“å‰é—®é¢˜ID
        next_question_id = analysis.get("next_question_id")
        if next_question_id == "assessment_complete":
            next_question_id = None
            analysis["assessment_complete"] = True
        
        # æ ¹æ®next_question_idåŠ¨æ€æ›´æ–°current_disorder_focus
        updated_disorder_focus = state.get("current_disorder_focus", "mood_disorders")
        if next_question_id:
            if next_question_id.startswith("anxiety"):
                updated_disorder_focus = "anxiety_disorders"
            elif next_question_id.startswith("depression"):
                updated_disorder_focus = "mood_disorders"
            elif next_question_id.startswith("ocd"):
                updated_disorder_focus = "obsessive_compulsive"
            elif next_question_id.startswith("ptsd"):
                updated_disorder_focus = "trauma_related"
            elif next_question_id.startswith("psychotic"):
                updated_disorder_focus = "psychotic_disorders"
        
        # æ ¹æ®ä¸‹ä¸€ä¸ªé—®é¢˜IDæ›´æ–°å½“å‰è¯é¢˜
        topic_mapping = {
            "depression_screening": "æŠ‘éƒç—‡ç­›æŸ¥",
            "anxiety_screening": "ç„¦è™‘ç—‡ç­›æŸ¥",
            "ocd_screening": "å¼ºè¿«ç—‡ç­›æŸ¥",
            "ptsd_screening": "åˆ›ä¼¤ååº”æ¿€éšœç¢ç­›æŸ¥",
            "psychotic_screening": "ç²¾ç¥ç—…æ€§éšœç¢ç­›æŸ¥",
            "initial": "åˆå§‹é—®è¯Š",
            "initial_screening": "åˆå§‹ç­›æŸ¥"
        }
        
        updated_topic = topic_mapping.get(next_question_id, state.get("current_topic", "é—®è¯Šä¸­"))
        if analysis.get("assessment_complete", False):
            updated_topic = "è¯„ä¼°å·²å®Œæˆ"
        
        return {
            **updated_state_with_criteria,
            "messages": state["messages"] + [ai_response],
            "user_responses": updated_responses,
            "conversation_history": updated_history,
            "emergency_situation": analysis["risk_level"] == "high",
            "risk_level": analysis["risk_level"],
            "risk_indicators": analysis.get("risk_indicators", []),
            "emotional_state": analysis["emotional_state"],
            "understanding_summary": analysis["understanding_summary"],
            "current_analysis": analysis,
            "current_question_id": next_question_id,
            "current_disorder_focus": updated_disorder_focus,  # åº”ç”¨æ›´æ–°çš„éšœç¢å…³æ³¨ç±»å‹
            "assessment_complete": analysis.get("assessment_complete", False),
            "needs_followup": False,  # ä¸å†éœ€è¦å•ç‹¬çš„è¿½é—®æµç¨‹
            "session_start_time": state["session_start_time"],
            "question_sequence": state["question_sequence"] + [current_question_id] if current_question_id else state["question_sequence"],
            "assessment_duration": state["assessment_duration"] + 1 if current_question_id else state["assessment_duration"],
            "user_engagement_level": "high" if analysis["risk_level"] == "high" else "medium",
            "response_detail_level": "detailed" if len(analysis.get("risk_indicators", [])) > 0 else "moderate",
            "symptoms_identified": state["symptoms_identified"] + ([current_question.text] if current_question else ["åˆå§‹é—®è¯Š"]),
            "domains_assessed": state["domains_assessed"] + ([current_question.category.value] if current_question else ["initial_screening"]),
            "severity_indicators": {**state["severity_indicators"], **({current_question.category.value: analysis["risk_level"]} if current_question else {"initial_screening": analysis["risk_level"]})},
            "chief_complaint": state["chief_complaint"] if state["chief_complaint"] else (last_user_message if current_question_id == "initial" else state["chief_complaint"]),
            "conversation_mode": "assessment_complete" if analysis.get("assessment_complete", False) else state["conversation_mode"],
            "chat_therapist_active": True if analysis.get("assessment_complete", False) else state["chat_therapist_active"],
            "mode_detection_result": state["mode_detection_result"],
            "current_topic": updated_topic,
            "is_follow_up": state["is_follow_up"]
        }
    
    def _get_next_question_info(self, current_question_id: str, user_response: str, state: InterviewState = None) -> str:
        """è·å–ä¸‹ä¸€ä¸ªé—®é¢˜çš„ä¿¡æ¯ç”¨äºç”Ÿæˆå›åº”ï¼ŒåŸºäºè¯Šæ–­æ ‡å‡†åŠ¨æ€é€‰æ‹©"""
        print("=" * 80)
        print("ğŸ” DEBUG - _get_next_question_info æ–¹æ³•å¼€å§‹", flush=True)
        print(f"ğŸ“¥ è¾“å…¥å‚æ•°:")
        print(f"   current_question_id: {current_question_id}")
        print(f"   user_response: {user_response[:100]}..." if len(user_response) > 100 else f"   user_response: {user_response}")
        print(f"   stateå­˜åœ¨: {state is not None}")
        
        if not current_question_id or current_question_id == "initial":
            print("ğŸ”„ é€»è¾‘åˆ†æ”¯: åˆå§‹é—®è¯Šé˜¶æ®µ")
            result = "é—®é¢˜ç›®çš„ï¼šå¼€å§‹å¿ƒç†å¥åº·è¯„ä¼°ï¼Œè¯¢é—®ç”¨æˆ·ç›®å‰æœ€ä¸»è¦çš„å›°æ‰°ï¼Œå¦‚æœç”¨æˆ·å·²ç»è¡¨è¾¾äº†å›°æ‰°ï¼Œåˆ™å®‰æ…°å¹¶è¿½é—®ç”¨æˆ·çš„ä¸»è¯‰ã€‚"
            print(f"ğŸ“¤ è¿”å›ç»“æœ: {result}")
            print("=" * 80)
            return result
        
        # è·å–å½“å‰å…³æ³¨çš„éšœç¢ç±»å‹å’Œå¯¹åº”çš„è¯Šæ–­æ ‡å‡†
        current_disorder = state.get("current_disorder_focus", "mood_disorders") if state else "mood_disorders"
        assessed_criteria = state.get("assessed_criteria", {}) if state else {}
        
        print(f"ğŸ“Š çŠ¶æ€æ•°æ®:")
        print(f"   current_disorder: {current_disorder}")
        print(f"   assessed_criteria: {assessed_criteria}")
        
        # å¦‚æœæ˜¯åˆå§‹é—®è¯Šä¸”ç”¨æˆ·æåŠäº†æŠ‘éƒç—‡çŠ¶ï¼Œä¼˜å…ˆå®‰æ’æŠ‘éƒç—‡ç­›æŸ¥
        if (not current_question_id or current_question_id == "initial") and user_response:
            print("ğŸ”„ é€»è¾‘åˆ†æ”¯: æ£€æŸ¥åˆå§‹é—®è¯Šä¸­çš„ç—‡çŠ¶å…³é”®è¯")
            response_lower = user_response.lower()
            print(f"   ç”¨æˆ·å›ç­”(å°å†™): {response_lower}")
            
            depression_keywords = ["æŠ‘éƒ", "éƒé—·", "ä½è½", "æ²®ä¸§", "æ‚²ä¼¤", "éš¾è¿‡"]
            anxiety_keywords = ["ç„¦è™‘", "ç´§å¼ ", "æ‹…å¿ƒ", "ææ…Œ", "å®³æ€•"]
            
            depression_found = [kw for kw in depression_keywords if kw in response_lower]
            anxiety_found = [kw for kw in anxiety_keywords if kw in response_lower]
            
            print(f"   æŠ‘éƒå…³é”®è¯åŒ¹é…: {depression_found}")
            print(f"   ç„¦è™‘å…³é”®è¯åŒ¹é…: {anxiety_found}")
            
            if depression_found:
                result = "ä¸‹ä¸€æ­¥å°†è¿›è¡ŒæŠ‘éƒç—‡çŠ¶è¯„ä¼°ï¼Œè¯¢é—®ç”¨æˆ·å…³äºæƒ…ç»ªä½è½çš„å…·ä½“æƒ…å†µ"
                print(f"ğŸ“¤ è¿”å›ç»“æœ(æŠ‘éƒç—‡çŠ¶): {result}")
                print("=" * 80)
                return result
            elif anxiety_found:
                result = "ä¸‹ä¸€æ­¥å°†è¿›è¡Œç„¦è™‘ç—‡çŠ¶è¯„ä¼°ï¼Œè¯¢é—®ç”¨æˆ·å…³äºç„¦è™‘æ‹…å¿ƒçš„å…·ä½“æƒ…å†µ"
                print(f"ğŸ“¤ è¿”å›ç»“æœ(ç„¦è™‘ç—‡çŠ¶): {result}")
                print("=" * 80)
                return result
        
        # ä¿®å¤ï¼šå°†current_disorderæ˜ å°„åˆ°æ­£ç¡®çš„ç±»å‹
        disorder_type_mapping = {
            "anxiety_screening": "anxiety_disorders",
            "depression_screening": "mood_disorders", 
            "mood_disorders": "mood_disorders",
            "anxiety_disorders": "anxiety_disorders",
            "obsessive_compulsive": "obsessive_compulsive",
            "trauma_related": "trauma_related",
            "psychotic_disorders": "psychotic_disorders"
        }
        
        print(f"ğŸ”„ é€»è¾‘åˆ†æ”¯: éšœç¢ç±»å‹æ˜ å°„")
        print(f"   disorder_type_mapping: {disorder_type_mapping}")
        
        # è·å–å¯¹åº”éšœç¢çš„è¯Šæ–­æ ‡å‡†
        disorder_mapping = {
            "mood_disorders": "major_depression",
            "anxiety_disorders": "generalized_anxiety", 
            "psychotic_disorders": None  # ç²¾ç¥ç—…æ€§éšœç¢æš‚æ—¶ä¸ä½¿ç”¨è¯¦ç»†æ ‡å‡†
        }
        
        print(f"   disorder_mapping: {disorder_mapping}")
        
        # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„disorderç±»å‹
        mapped_disorder_type = disorder_type_mapping.get(current_disorder, current_disorder)
        disorder_key = disorder_mapping.get(mapped_disorder_type)
        
        print(f"   mapped_disorder_type: {mapped_disorder_type}")
        print(f"   disorder_key: {disorder_key}")
        
        if disorder_key and disorder_key in scid5_kb.diagnostic_criteria:
            print(f"ğŸ”„ é€»è¾‘åˆ†æ”¯: ä½¿ç”¨è¯Šæ–­æ ‡å‡† - {disorder_key}")
            criteria = scid5_kb.diagnostic_criteria[disorder_key]
            assessed_for_disorder = assessed_criteria.get(mapped_disorder_type, [])
            
            print(f"   è¯Šæ–­æ ‡å‡†æ•°é‡: {len(criteria.criteria)}")
            print(f"   æ‰€æœ‰æ ‡å‡†: {criteria.criteria}")
            print(f"   å·²è¯„ä¼°æ ‡å‡†: {assessed_for_disorder}")
            
            # æ‰¾å‡ºå°šæœªè¯„ä¼°çš„ç—‡çŠ¶æ ‡å‡†
            remaining_criteria = [c for c in criteria.criteria if c not in assessed_for_disorder]
            print(f"   å‰©ä½™å¾…è¯„ä¼°æ ‡å‡†: {remaining_criteria}")
            
            # æ ¹æ®å°šæœªè¯„ä¼°çš„ç—‡çŠ¶æ ‡å‡†ç”Ÿæˆå…·ä½“é—®é¢˜
            if remaining_criteria:
                next_symptom = remaining_criteria[0]
                print(f"   é€‰æ‹©ä¸‹ä¸€ä¸ªç—‡çŠ¶: {next_symptom}")
                
                # æ ¹æ®ç—‡çŠ¶æ ‡å‡†ç”Ÿæˆå¯¹åº”çš„é—®é¢˜
                symptom_questions = {
                    "æƒ…ç»ªä½è½": "åœ¨è¿‡å»çš„ä¸¤å‘¨å†…ï¼Œæ‚¨æ˜¯å¦å‡ ä¹æ¯å¤©éƒ½æ„Ÿåˆ°æƒ…ç»ªä½è½ã€æ²®ä¸§æˆ–ç»æœ›ï¼Ÿ",
                    "å…´è¶£ä¸§å¤±": "åœ¨è¿‡å»çš„ä¸¤å‘¨å†…ï¼Œæ‚¨æ˜¯å¦å¯¹å¹³æ—¶æ„Ÿå…´è¶£æˆ–æ„‰å¿«çš„æ´»åŠ¨æ˜æ˜¾å¤±å»å…´è¶£ï¼Ÿ",
                    "é£Ÿæ¬²æ”¹å˜": "åœ¨è¿‡å»çš„ä¸¤å‘¨å†…ï¼Œæ‚¨çš„é£Ÿæ¬²æ˜¯å¦æœ‰æ˜æ˜¾å˜åŒ–ï¼Ÿæ¯”å¦‚é£Ÿæ¬²æ˜¾è‘—å¢åŠ æˆ–å‡å°‘ï¼Œä½“é‡æœ‰æ˜æ˜¾å˜åŒ–å—ï¼Ÿ",
                    "ç¡çœ éšœç¢": "åœ¨è¿‡å»çš„ä¸¤å‘¨å†…ï¼Œæ‚¨çš„ç¡çœ æ€ä¹ˆæ ·ï¼Ÿæ˜¯å¦æœ‰å¤±çœ ã€æ—©é†’æˆ–ç¡çœ è¿‡å¤šçš„æƒ…å†µï¼Ÿ",
                    "ç²¾ç¥è¿åŠ¨æ”¹å˜": "åœ¨è¿‡å»çš„ä¸¤å‘¨å†…ï¼Œæ‚¨æ˜¯å¦æ„Ÿåˆ°åç«‹ä¸å®‰ï¼Œæˆ–è€…åŠ¨ä½œå’Œæ€ç»´æ¯”å¹³æ—¶ç¼“æ…¢ï¼Ÿ",
                    "ç–²åŠ³": "åœ¨è¿‡å»çš„ä¸¤å‘¨å†…ï¼Œæ‚¨æ˜¯å¦å‡ ä¹æ¯å¤©éƒ½æ„Ÿåˆ°ç–²åŠ³æˆ–ç²¾åŠ›ä¸è¶³ï¼Ÿ",
                    "æ— ä»·å€¼æ„Ÿ/ç½ªæ¶æ„Ÿ": "åœ¨è¿‡å»çš„ä¸¤å‘¨å†…ï¼Œæ‚¨æ˜¯å¦ç»å¸¸æ„Ÿåˆ°è‡ªå·±æ²¡æœ‰ä»·å€¼ï¼Œæˆ–è€…æœ‰è¿‡åº¦çš„ã€ä¸åˆç†çš„ç½ªæ¶æ„Ÿï¼Ÿ",
                    "æ³¨æ„åŠ›é—®é¢˜": "åœ¨è¿‡å»çš„ä¸¤å‘¨å†…ï¼Œæ‚¨æ˜¯å¦å‘ç°è‡ªå·±éš¾ä»¥é›†ä¸­æ³¨æ„åŠ›ï¼Œæˆ–è€…åœ¨åšå†³å®šæ—¶çŠ¹è±«ä¸å†³ï¼Ÿ",
                    "æ­»äº¡å¿µå¤´": "åœ¨è¿‡å»çš„ä¸¤å‘¨å†…ï¼Œæ‚¨æ˜¯å¦åå¤æƒ³åˆ°æ­»äº¡ï¼Œæˆ–è€…æœ‰è¿‡ä¼¤å®³è‡ªå·±çš„æƒ³æ³•ï¼Ÿ",
                    "è¿‡åº¦ç„¦è™‘å’Œæ‹…å¿ƒ": "åœ¨è¿‡å»çš„6ä¸ªæœˆå†…ï¼Œæ‚¨æ˜¯å¦ç»å¸¸æ„Ÿåˆ°è¿‡åº¦çš„æ‹…å¿ƒæˆ–ç„¦è™‘ï¼Œéš¾ä»¥æ§åˆ¶è¿™äº›æ‹…å¿ƒï¼Ÿ",
                    "åç«‹ä¸å®‰": "å½“æ‚¨æ„Ÿåˆ°ç„¦è™‘æ—¶ï¼Œæ˜¯å¦ç»å¸¸æ„Ÿåˆ°åç«‹ä¸å®‰æˆ–ç´§å¼ ä¸å®‰ï¼Ÿ",
                    "å®¹æ˜“ç–²åŠ³": "æ‚¨æ˜¯å¦å› ä¸ºæ‹…å¿ƒå’Œç„¦è™‘è€Œå®¹æ˜“æ„Ÿåˆ°ç–²åŠ³ï¼Ÿ",
                    "æ³¨æ„åŠ›é›†ä¸­å›°éš¾": "ç„¦è™‘æ˜¯å¦å½±å“äº†æ‚¨é›†ä¸­æ³¨æ„åŠ›çš„èƒ½åŠ›ï¼Ÿ",
                    "æ˜“æ€’": "æ‚¨æ˜¯å¦å‘ç°è‡ªå·±æ¯”å¹³æ—¶æ›´å®¹æ˜“ç”Ÿæ°”æˆ–çƒ¦èºï¼Ÿ",
                    "è‚Œè‚‰ç´§å¼ ": "æ‚¨æ˜¯å¦ç»å¸¸æ„Ÿåˆ°è‚Œè‚‰ç´§å¼ æˆ–èº«ä½“åƒµç¡¬ï¼Ÿ"
                }
                
                question_text = symptom_questions.get(next_symptom, f"è¯·å‘Šè¯‰æˆ‘å…³äº{next_symptom}æ–¹é¢çš„æƒ…å†µ")
                next_question_info = f"è¯„ä¼°{next_symptom}"
                
                print(f"   å¯¹åº”é—®é¢˜æ–‡æœ¬: {question_text}")
                print(f"ğŸ“¤ è¿”å›ç»“æœ: {next_question_info}")
                print("=" * 80)
                return next_question_info
            else:
                print("ğŸ”„ é€»è¾‘åˆ†æ”¯: å½“å‰éšœç¢è¯„ä¼°å®Œæˆ")
                next_question_info = "è¯„ä¼°å·²å®Œæˆï¼Œç”ŸæˆsummaryæŠ¥å‘Šå¹¶è¿›å…¥CBTç–—æ„ˆæ¨¡å¼"
                print(f"ğŸ“¤ è¿”å›ç»“æœ: {next_question_info}")
                print("=" * 80)
                return next_question_info
        else:
            print(f"ğŸ”„ é€»è¾‘åˆ†æ”¯: ä½¿ç”¨åŸæœ‰é€»è¾‘ (disorder_key: {disorder_key})")
            print(f"   scid5_kb.diagnostic_criteria ä¸­åŒ…å«çš„é”®: {list(scid5_kb.diagnostic_criteria.keys()) if hasattr(scid5_kb, 'diagnostic_criteria') else 'æ— diagnostic_criteria'}")
            
            # ä½¿ç”¨åŸæœ‰é€»è¾‘ä½œä¸ºå¤‡é€‰
            next_question = scid5_kb.get_next_question(current_question_id, user_response)
            print(f"   scid5_kb.get_next_question è¿”å›: {next_question}")
            
            if next_question:
                next_question_info = f"{getattr(next_question, 'purpose', 'è¯„ä¼°ç›¸å…³ç—‡çŠ¶')}"
                print(f"ğŸ“¤ è¿”å›ç»“æœ(åŸæœ‰é€»è¾‘): {next_question_info}")
            else:
                next_question_info = "è¯„ä¼°å·²å®Œæˆï¼Œç”ŸæˆsummaryæŠ¥å‘Šå¹¶è¿›å…¥CBTç–—æ„ˆæ¨¡å¼"
                print(f"ğŸ“¤ è¿”å›ç»“æœ(è¯„ä¼°å®Œæˆ): {next_question_info}")
            
            print("=" * 80)
            return next_question_info
    
    def _update_assessed_criteria(self, state: InterviewState, current_question_id: str, user_response: str) -> InterviewState:
        """æ›´æ–°å·²è¯„ä¼°çš„ç—‡çŠ¶æ ‡å‡† - åªè®°å½•å·²é—®è¿‡çš„é—®é¢˜ï¼Œä¸åšç–¾ç—…åˆ¤æ–­"""
        if not current_question_id or current_question_id == "initial":
            return state
            
        # æ ¹æ®é—®é¢˜IDå’Œå›ç­”æ›´æ–°å·²è¯„ä¼°çš„ç—‡çŠ¶æ ‡å‡†
        current_disorder = state.get("current_disorder_focus", "mood_disorders")
        assessed_criteria = state.get("assessed_criteria", {}).copy()
        
        # åˆå§‹åŒ–å½“å‰éšœç¢çš„è¯„ä¼°è®°å½•
        if current_disorder not in assessed_criteria:
            assessed_criteria[current_disorder] = []
            
        # åŠ¨æ€ç¡®å®šå½“å‰é—®é¢˜å¯¹åº”çš„ç—‡çŠ¶æ ‡å‡†
        current_symptom = self._get_current_symptom_from_question(current_disorder, assessed_criteria.get(current_disorder, []), current_question_id)
        
        if current_symptom:
            # åªè®°å½•å·²é—®è¿‡çš„ç—‡çŠ¶æ ‡å‡†ï¼Œä¸åšç–¾ç—…åˆ¤æ–­
            if current_symptom not in assessed_criteria[current_disorder]:
                assessed_criteria[current_disorder].append(current_symptom)
                
                print(f"ğŸ” DEBUG - æ›´æ–°å·²è¯„ä¼°æ ‡å‡†:", flush=True)
                print(f"   éšœç¢ç±»å‹: {current_disorder}")
                print(f"   æ–°å¢ç—‡çŠ¶æ ‡å‡†: {current_symptom}")
                print(f"   å½“å‰å·²è¯„ä¼°æ ‡å‡†: {assessed_criteria[current_disorder]}")
        
        # æ›´æ–°çŠ¶æ€ - ç§»é™¤criteria_resultsï¼Œç–¾ç—…åˆ¤æ–­ç•™ç»™æŠ¥å‘Šç”Ÿæˆé˜¶æ®µ
        updated_state = state.copy()
        updated_state["assessed_criteria"] = assessed_criteria
        
        return updated_state
    
    def _get_current_symptom_from_question(self, disorder_type: str, assessed_symptoms: list, question_id: str) -> str:
        """æ ¹æ®éšœç¢ç±»å‹å’Œå·²è¯„ä¼°ç—‡çŠ¶ï¼Œç¡®å®šå½“å‰é—®é¢˜å¯¹åº”çš„ç—‡çŠ¶æ ‡å‡†"""
        # éšœç¢ç±»å‹æ˜ å°„
        disorder_type_mapping = {
            "anxiety_screening": "anxiety_disorders",
            "depression_screening": "mood_disorders", 
            "mood_disorders": "mood_disorders",
            "anxiety_disorders": "anxiety_disorders",
            "obsessive_compulsive": "obsessive_compulsive",
            "trauma_related": "trauma_related",
            "psychotic_disorders": "psychotic_disorders"
        }
        
        # è·å–å¯¹åº”éšœç¢çš„è¯Šæ–­æ ‡å‡†
        disorder_mapping = {
            "mood_disorders": "major_depression",
            "anxiety_disorders": "generalized_anxiety", 
            "psychotic_disorders": None
        }
        
        mapped_disorder_type = disorder_type_mapping.get(disorder_type, disorder_type)
        disorder_key = disorder_mapping.get(mapped_disorder_type)
        
        if disorder_key and disorder_key in scid5_kb.diagnostic_criteria:
            criteria = scid5_kb.diagnostic_criteria[disorder_key]
            
            # æ‰¾å‡ºå°šæœªè¯„ä¼°çš„ç—‡çŠ¶æ ‡å‡†
            remaining_criteria = [c for c in criteria.criteria if c not in assessed_symptoms]
            
            if remaining_criteria:
                # è¿”å›ä¸‹ä¸€ä¸ªå¾…è¯„ä¼°çš„ç—‡çŠ¶æ ‡å‡†
                next_symptom = remaining_criteria[0]
                print(f"ğŸ” DEBUG - _get_current_symptom_from_question:", flush=True)
                print(f"   éšœç¢ç±»å‹: {disorder_type} -> {mapped_disorder_type}")
                print(f"   è¯Šæ–­æ ‡å‡†: {disorder_key}")
                print(f"   æ‰€æœ‰æ ‡å‡†: {criteria.criteria}")
                print(f"   å·²è¯„ä¼°: {assessed_symptoms}")
                print(f"   å‰©ä½™å¾…è¯„ä¼°: {remaining_criteria}")
                print(f"   å½“å‰ç—‡çŠ¶: {next_symptom}")
                return next_symptom
        
        # å¦‚æœæ— æ³•ä»è¯Šæ–­æ ‡å‡†ä¸­ç¡®å®šï¼Œä½¿ç”¨å¤‡ç”¨é€»è¾‘
        fallback_mapping = {
            "depression_screening": "æƒ…ç»ªä½è½",
            "depression_interest": "å…´è¶£ä¸§å¤±", 
            "anxiety_screening": "è¿‡åº¦ç„¦è™‘å’Œæ‹…å¿ƒ",
            "panic_screening": "æƒŠæå‘ä½œ"
        }
        
        return fallback_mapping.get(question_id, "å…¶ä»–ç—‡çŠ¶")
    
    def ask_question(self, state: InterviewState) -> InterviewState:
        """ç‹¬ç«‹æé—®æ–¹æ³•ï¼ˆä¿ç•™ç”¨äºç‰¹æ®Šæƒ…å†µï¼‰"""
        # è¿™ä¸ªæ–¹æ³•ç°åœ¨ä¸»è¦ç”¨äºç‰¹æ®Šæƒ…å†µï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹understand_and_respondå·²ç»åŒ…å«äº†æé—®
        return state


# =========================
# ç´§æ€¥æƒ…å†µå¤„ç†å™¨
# =========================

class EmergencyHandler:
    """ç´§æ€¥æƒ…å†µå¤„ç†å™¨"""
    
    def __init__(self, llm):
        self.llm = llm
    
    def check_emergency(self, state: InterviewState) -> InterviewState:
        """æ£€æŸ¥ç´§æ€¥æƒ…å†µ"""
        # è·å–æœ€è¿‘çš„ç”¨æˆ·å›ç­”
        last_response = ""
        for msg in reversed(state["messages"]):
            if isinstance(msg, HumanMessage):
                last_response = msg.content.lower()
                break
        
        # ä½¿ç”¨LLMè¿›è¡Œæ›´æ™ºèƒ½çš„é£é™©è¯„ä¼°
        risk_prompt = PromptTemplates.get_emergency_risk_assessment_prompt(
            last_response, state.get("current_question_id", "")
        )
        
        print("=" * 50)
        print("ğŸ” DEBUG - CHECK_EMERGENCY LLM CALL", flush=True)
        print("PROMPT:")
        print(risk_prompt)
        print("=" * 50)
        
        response = self.llm.invoke([HumanMessage(content=risk_prompt)])
        
        print("RESPONSE:")
        print(response.content)
        print("=" * 50)
        
        try:
            risk_analysis = json.loads(response.content)
            emergency_detected = risk_analysis.get("immediate_action_needed", False)
        except:
            # å¦‚æœLLMåˆ†æå¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯æ£€æµ‹ä½œä¸ºå¤‡é€‰
            emergency_detected = any(keyword in last_response for keyword in KeywordLibrary.EMERGENCY_KEYWORDS)
        
        return {
            **state,
            "emergency_situation": emergency_detected
        }
    
    def emergency_response(self, state: InterviewState) -> InterviewState:
        """å¤„ç†ç´§æ€¥æƒ…å†µ"""
        emergency_message = AIMessage(content=PromptTemplates.EMERGENCY_RESPONSE_MESSAGE)
        
        return {
            **state,
            "messages": state["messages"] + [emergency_message],
            "assessment_complete": True
        }


# =========================
# å“åº”ç”Ÿæˆå™¨
# =========================

class ResponseGenerator:
    """å›åº”ç”Ÿæˆå™¨"""
    
    def __init__(self, llm):
        self.llm = llm
        self.workflow_mode = "adaptive"  # é»˜è®¤æ¨¡å¼
    
    def generate_summary(self, state: InterviewState) -> InterviewState:
        """ç”Ÿæˆè¯„ä¼°æ€»ç»“"""
        assessment_summary = scid5_kb.generate_assessment_summary()
        
        # ä½¿ç”¨LLMç”Ÿæˆæ›´è¯¦ç»†å’Œä¸ªæ€§åŒ–çš„æ€»ç»“
        prompt = PromptTemplates.get_assessment_summary_prompt(
            state["conversation_history"], 
            state["user_responses"], 
            assessment_summary
        )
        
        print("=" * 50)
        print("ğŸ” DEBUG - GENERATE_SUMMARY LLM CALL", flush=True)
        print("PROMPT:")
        print(prompt)
        print("=" * 50)
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        
        print("RESPONSE:")
        print(response.content)
        print("=" * 50)
        
        detailed_summary = response.content
        
        # æ ¹æ®å·¥ä½œæ¨¡å¼æ·»åŠ ä¸åŒçš„ç»“æŸè¯­
        if self.workflow_mode == "structured":
            detailed_summary += PromptTemplates.STRUCTURED_MODE_COMPLETION_MESSAGE
        
        summary_message = AIMessage(content=detailed_summary)
        
        return {
            **state,
            "messages": state["messages"] + [summary_message],
            "summary": detailed_summary,
            "assessment_complete": True,
            "conversation_mode": "assessment_complete",
            "chat_therapist_active": True
        }
    
    def fallback_response(self, current_state: dict, user_message: str) -> tuple:
        """åå¤‡å“åº”æ–¹æ³•"""
        try:
            fallback_prompt = PromptTemplates.get_fallback_prompt(user_message)
            system_content = PromptTemplates.get_fallback_response_system_content(
                current_state.get("current_question_id", "")
            )
            
            response = self.llm.invoke([
                SystemMessage(content=system_content),
                HumanMessage(content=fallback_prompt)
            ])
            
            return response.content, current_state
            
        except Exception as e:
            print(f"Fallback response error: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ç†è§£æ‚¨çš„æ„æ€ã€‚è®©æˆ‘ä»¬ç»§ç»­æˆ‘ä»¬çš„å¯¹è¯å§ã€‚", current_state