"""
å¯¹è¯æ¨¡å¼å¤„ç†æ¨¡å—
åŒ…å«å¯¹è¯æ¨¡å¼æ£€æµ‹å’ŒCBTç–—æ„ˆå¸ˆå“åº”åŠŸèƒ½
"""

import json
from langchain.schema import HumanMessage, SystemMessage, AIMessage

from agent import InterviewState
from workflow import EnhancedIntentDetector


class ConversationModeHandler:
    """å¯¹è¯æ¨¡å¼å¤„ç†å™¨ - é›†æˆå¢å¼ºæ„å›¾æ£€æµ‹"""
    
    def __init__(self, llm, workflow_mode: str = "adaptive"):
        self.llm = llm
        self.workflow_mode = workflow_mode
        
        # åˆå§‹åŒ–å¢å¼ºæ„å›¾æ£€æµ‹å™¨
        self.intent_detector = EnhancedIntentDetector(llm, workflow_mode)
        
        # ä¿ç•™åŸæœ‰çš„ç®€å•æ£€æµ‹ä½œä¸ºåå¤‡
        self.simple_detection_enabled = True
    
    def detect_conversation_mode(self, state: InterviewState) -> InterviewState:
        """æ£€æµ‹å¯¹è¯æ¨¡å¼ - ä½¿ç”¨å¢å¼ºæ£€æµ‹å™¨"""
        try:
            # ä½¿ç”¨å¢å¼ºçš„æ„å›¾æ£€æµ‹
            result = self.intent_detector.detect_conversation_mode(state)
            
            # æ·»åŠ è°ƒè¯•ä¿¡æ¯
            if result.get("mode_detection_result"):
                print("ğŸ” å¢å¼ºæ„å›¾æ£€æµ‹ç»“æœï¼š")
                print(f"  æ¨¡å¼: {result['conversation_mode']}")
                print(f"  ç½®ä¿¡åº¦: {result['mode_detection_result'].get('confidence', 'N/A')}")
                print(f"  åŸå› : {result['mode_detection_result'].get('reason', 'N/A')}")
            
            return result
                
        except Exception as e:
            print(f"âš ï¸ å¢å¼ºæ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ£€æµ‹: {e}")
            
            # åå¤‡ï¼šä½¿ç”¨åŸæœ‰çš„ç®€å•æ£€æµ‹é€»è¾‘
            if self.simple_detection_enabled:
                return self._simple_detection_fallback(state)
            else:
                raise e
    
    def _simple_detection_fallback(self, state: InterviewState) -> InterviewState:
        """ç®€å•æ£€æµ‹åå¤‡é€»è¾‘ï¼ˆåŸæœ‰é€»è¾‘çš„ç®€åŒ–ç‰ˆï¼‰"""
        print("ğŸ”„ ä½¿ç”¨ç®€å•æ£€æµ‹åå¤‡é€»è¾‘")
        
        # å¦‚æœå·²ç»å®Œæˆè¯„ä¼°ï¼Œé»˜è®¤è¿›å…¥é—²èŠæ¨¡å¼
        if state.get("assessment_complete", False):
            return {
                **state,
                "conversation_mode": "assessment_complete",
                "chat_therapist_active": True,
                "mode_detection_result": {
                    "detected_mode": "assessment_complete",
                    "confidence": 1.0,
                    "reason": "è¯„ä¼°å·²å®Œæˆï¼Œè¿›å…¥åç»­é—²èŠæ¨¡å¼"
                }
            }
        
        # è·å–å½“å‰ä¼šè¯è½®æ•°
        current_turn = state.get("conversation_turn_count", 0)
        interview_locked = state.get("interview_mode_locked", False)
        
        # å¦‚æœé—®è¯Šæ¨¡å¼å·²é”å®šï¼Œå¼ºåˆ¶ç»§ç»­é—®è¯Š
        if interview_locked:
            return {
                **state,
                "conversation_mode": "continue_interview",
                "chat_therapist_active": False,
                "conversation_turn_count": current_turn + 1,
                "mode_detection_result": {
                    "detected_mode": "continue_interview",
                    "confidence": 1.0,
                    "reason": "é—®è¯Šæ¨¡å¼å·²é”å®šï¼Œç»§ç»­è¿›è¡Œé—®è¯Šç›´è‡³å®Œæˆ"
                }
            }
        
        # ç»“æ„åŒ–æ¨¡å¼ï¼šå¦‚æœè¯„ä¼°æœªå®Œæˆï¼Œå¼ºåˆ¶è¿›å…¥é—®è¯Šæ¨¡å¼
        if (self.workflow_mode == "structured" and 
            not state.get("assessment_complete", False)):
            print(f"ğŸ”’ ç»“æ„åŒ–æ¨¡å¼å¼ºåˆ¶é”å®šé—®è¯Šæµç¨‹ - è¯„ä¼°æœªå®Œæˆ")
            return {
                **state,
                "conversation_mode": "continue_interview",
                "chat_therapist_active": False,
                "conversation_turn_count": current_turn + 1,
                "interview_mode_locked": True,
                "mode_detection_result": {
                    "detected_mode": "continue_interview",
                    "confidence": 1.0,
                    "reason": "ç»“æ„åŒ–æ¨¡å¼ï¼šå¼ºåˆ¶è¿›å…¥é—®è¯Šæµç¨‹å¹¶é”å®š"
                }
            }
        
        # è·å–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
        user_messages = [msg for msg in state["messages"] if isinstance(msg, HumanMessage)]
        if not user_messages:
            return {
                **state,
                "conversation_mode": "interview",
                "conversation_turn_count": current_turn + 1,
                "mode_detection_result": {
                    "detected_mode": "interview",
                    "confidence": 0.8,
                    "reason": "æ²¡æœ‰ç”¨æˆ·è¾“å…¥ï¼Œé»˜è®¤å¼€å§‹é—®è¯Š"
                }
            }
        
        latest_user_message = user_messages[-1].content
        
        # ç®€å•å…³é”®è¯æ£€æµ‹
        chat_keywords = ["é—²èŠ", "èŠå¤©", "è°ˆå¿ƒ", "èŠèŠ", "éšä¾¿èŠ", "é™ªæˆ‘èŠ"]
        interview_keywords = ["æŠ‘éƒ", "ç„¦è™‘", "å¤±çœ ", "æƒ…ç»ª", "å¿ƒç†", "ç—‡çŠ¶", "å›°æ‰°", "é—®é¢˜"]
        
        if any(keyword in latest_user_message for keyword in chat_keywords):
            mode = "chat"
            will_lock = False
        elif any(keyword in latest_user_message for keyword in interview_keywords):
            mode = "interview"
            will_lock = True
        else:
            # é»˜è®¤åˆ‡æ¢åˆ°CBTé—²èŠæ¨¡å¼ï¼ˆæ²¡æœ‰æ˜ç¡®é—®è¯Šæ„å›¾æ—¶ï¼‰
            mode = "chat"
            will_lock = False
            print(f"ğŸ”„ ç®€å•æ£€æµ‹ï¼šæ²¡æœ‰æ˜ç¡®æ„å›¾ï¼Œåˆ‡æ¢åˆ°CBTé—²èŠæ¨¡å¼", flush=True)
        
        return {
            **state,
            "conversation_mode": mode,
            "chat_therapist_active": mode == "chat",
            "conversation_turn_count": current_turn + 1,
            "interview_mode_locked": will_lock,
            "mode_detection_result": {
                "detected_mode": mode,
                "confidence": 0.7,
                "reason": "ç®€å•å…³é”®è¯æ£€æµ‹åå¤‡é€»è¾‘",
                "fallback_used": True
            }
        }
    
    def chat_therapist_response(self, state: InterviewState) -> InterviewState:
        """CBTç–—æ„ˆå¸ˆå“åº” - å½“ç”¨æˆ·æƒ³è¦é—²èŠæ—¶æä¾›å¿ƒç†æ”¯æŒ"""
        user_messages = [msg for msg in state["messages"] if isinstance(msg, HumanMessage)]
        latest_user_message = user_messages[-1].content if user_messages else ""
        
        # æ›´æ–°å¯¹è¯å†å² - æ·»åŠ ä¸Šä¸€è½®AIå›å¤å’Œå½“å‰ç”¨æˆ·æ¶ˆæ¯ï¼ˆç±»ä¼¼ fallback_responseï¼‰
        updated_history = state.get("conversation_history", []).copy()
        
        # æ·»åŠ ä¸Šä¸€è½®çš„AIå›å¤ï¼ˆå¦‚æœå­˜åœ¨ä¸”ä¸æ˜¯åˆå§‹ä»‹ç»ï¼‰
        messages = state.get("messages", [])
        
        print(f"ğŸ” DEBUG - CBT Messagesæ•°é‡: {len(messages)}", flush=True)
        for i, msg in enumerate(messages):
            print(f"ğŸ” DEBUG - CBT Message[{i}]: {type(msg).__name__}", flush=True)
        
        # åªæœ‰å½“æœ‰çœŸæ­£çš„å¯¹è¯å†å²æ—¶ï¼Œæ‰æ·»åŠ AIå›å¤
        if len(messages) > 3:  # SystemMessage + AIMessage(intro) + HumanMessage + AIMessage(real_response)
            last_ai_message = None
            # ä»åå¾€å‰æ‰¾ï¼Œè·³è¿‡å¯èƒ½çš„åˆå§‹ä»‹ç»
            for msg in reversed(messages[2:]):  # è·³è¿‡å‰ä¸¤ä¸ªæ¶ˆæ¯ï¼ˆSystemMessage + åˆå§‹ä»‹ç»ï¼‰
                if isinstance(msg, AIMessage):
                    last_ai_message = msg.content.strip()
                    break
            if last_ai_message:
                updated_history.append(f"You: {last_ai_message}")
                print(f"ğŸ” DEBUG - CBTæ·»åŠ AIå†å²: {last_ai_message[:50]}...", flush=True)
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        updated_history.append(f"User: {latest_user_message}")
        print(f"ğŸ” DEBUG - CBTæ·»åŠ ç”¨æˆ·æ¶ˆæ¯: {latest_user_message}", flush=True)
        
        # è·å–æœ€è¿‘20è½®çš„å†å²è®°å½•ç”¨äºprompt
        recent_history = updated_history[-20:] if len(updated_history) > 0 else []
        history_context = "\n".join(recent_history) if recent_history else "æ— å¯¹è¯å†å²"
        
        # ä½¿ç”¨ç»Ÿä¸€çš„promptæ¨¡æ¿
        from prompts import PromptTemplates
        cbt_system_prompt = PromptTemplates.CBT_THERAPIST_SYSTEM_PROMPT
        
        # å¦‚æœæ˜¯è¯„ä¼°å®Œæˆåçš„é—²èŠ
        if state.get("conversation_mode") == "assessment_complete":
            cbt_system_prompt += PromptTemplates.CBT_ASSESSMENT_COMPLETE_ADDON
        
        try:
            # ç”ŸæˆåŒ…å«å†å²å¯¹è¯çš„CBTç–—æ„ˆå¸ˆå›å¤
            cbt_prompt = f"""## æœ€è¿‘å¯¹è¯å†å²ï¼š
{history_context}

è¯·åŸºäºå¯¹è¯å†å²ï¼Œç”Ÿæˆåˆé€‚çš„CBTç–—æ„ˆå¸ˆå›åº”ã€‚"""
            
            print("=" * 50)
            print("ğŸ” DEBUG - CBT_THERAPIST_RESPONSE LLM CALL", flush=True)
            print("SYSTEM PROMPT:")
            print(cbt_system_prompt)
            print("USER PROMPT:")
            print(cbt_prompt)
            print("=" * 50)
            
            cbt_response = self.llm.invoke([
                SystemMessage(content=cbt_system_prompt),
                HumanMessage(content=cbt_prompt)
            ])
            
            print("RESPONSE:")
            print(cbt_response.content)
            print("=" * 50)
            
            final_response = cbt_response.content
            
            # å¦‚æœæ˜¯è¯„ä¼°å®ŒæˆçŠ¶æ€ï¼Œæ·»åŠ æ„Ÿè°¢å’Œç¡®è®¤ä¿¡æ¯
            if state.get("conversation_mode") == "assessment_complete" and "æ„Ÿè°¢" not in final_response:
                completion_message = """æ„Ÿè°¢æ‚¨çš„å‚ä¸å’Œé…åˆï¼æˆ‘å·²ç»å®Œæˆäº†å¯¹æ‚¨çš„å¿ƒç†å¥åº·è¯„ä¼°ã€‚ç°åœ¨æˆ‘ä»¬å¯ä»¥è¿›è¡Œè½»æ¾çš„äº¤æµå’Œå¿ƒç†æ”¯æŒã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•æƒ³èŠçš„è¯é¢˜æˆ–éœ€è¦å¿ƒç†æ”¯æŒï¼Œæˆ‘å¾ˆä¹æ„é™ªä¼´æ‚¨ã€‚
                """
                final_response = completion_message + "\n\n" + final_response
            
            # åˆ›å»º AI å›å¤æ¶ˆæ¯å¹¶æ·»åŠ åˆ° messages ä¸­ï¼ˆç±»ä¼¼ fallback_responseï¼‰
            ai_response_message = AIMessage(content=final_response)
            
            # æ›´æ–°çŠ¶æ€ï¼ŒåŒ…å«æ›´æ–°åçš„å¯¹è¯å†å²å’Œæ¶ˆæ¯
            updated_state = state.copy()
            updated_state["conversation_history"] = updated_history
            updated_state["messages"] = state.get("messages", []) + [ai_response_message]
            updated_state["final_response"] = final_response
            updated_state["chat_therapist_active"] = True
            
            print(f"ğŸ” DEBUG - CBTæ·»åŠ AIå›å¤åˆ°messagesï¼Œæ–°çš„messagesæ•°é‡: {len(updated_state['messages'])}", flush=True)
            print(f"ğŸ” DEBUG - CBTå†å²è®°å½•æ¡æ•°: {len(updated_history)}", flush=True)
            
            return updated_state
            
        except Exception as e:
            print(f"CBTç–—æ„ˆå¸ˆå“åº”ç”Ÿæˆå¤±è´¥: {e}")
            # åå¤‡å“åº”
            fallback_response = PromptTemplates.CBT_FALLBACK_RESPONSE
            
            return {
                **state,
                "final_response": fallback_response,
                "chat_therapist_active": True
            }