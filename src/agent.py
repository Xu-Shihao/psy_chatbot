"""
ç»Ÿä¸€çš„Agentæ¨¡å—
æ•´åˆäº†æ‰€æœ‰Agentç›¸å…³çš„ç±»å‹å®šä¹‰ã€æ ¸å¿ƒåŠŸèƒ½å’Œå…·ä½“å®ç°
"""

from typing import Dict, List, Optional, TypedDict, Annotated, Tuple
from datetime import datetime
from langchain.schema import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI
from langgraph.graph.message import AnyMessage, add_messages

from config import config
from prompts import PromptTemplates


# =========================
# ç±»å‹å®šä¹‰
# =========================

class InterviewState(TypedDict):
    """
    é—®è¯ŠçŠ¶æ€ - åŒ…å«å®Œæ•´çš„ä¼šè¯çŠ¶æ€ä¿¡æ¯
    
    åŸºæœ¬çŠ¶æ€å­—æ®µï¼š
    - messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
    - current_question_id: å½“å‰é—®é¢˜ID
    - user_responses: ç”¨æˆ·å›ç­”è®°å½•
    - assessment_complete: è¯„ä¼°æ˜¯å¦å®Œæˆ
    - emergency_situation: æ˜¯å¦æœ‰ç´§æ€¥æƒ…å†µ
    - summary: è¯„ä¼°æ€»ç»“
    - needs_followup: æ˜¯å¦éœ€è¦è¿½é—®
    - conversation_history: å¯¹è¯å†å²è®°å½•
    - chief_complaint: ç”¨æˆ·ä¸»è¦è¯‰æ±‚
    - conversation_mode: å¯¹è¯æ¨¡å¼ ('idle', 'interview', 'chat', 'assessment_complete')
    - chat_therapist_active: CBTç–—æ„ˆå¸ˆæ˜¯å¦æ¿€æ´»
    - mode_detection_result: æ¨¡å¼æ£€æµ‹ç»“æœ
    - conversation_turn_count: ä¼šè¯è½®æ•°è®¡æ•°å™¨
    - interview_mode_locked: é—®è¯Šæ¨¡å¼æ˜¯å¦å·²é”å®š
    
    è¿½é—®å’Œåˆ†æå­—æ®µï¼š
    - followup_questions: è¿½é—®é—®é¢˜åˆ—è¡¨
    - risk_level: é£é™©ç­‰çº§ (low/medium/high)
    - risk_indicators: é£é™©æŒ‡æ ‡åˆ—è¡¨
    - emotional_state: ç”¨æˆ·æƒ…æ„ŸçŠ¶æ€æè¿°
    - content_complete: ç”¨æˆ·å›ç­”æ˜¯å¦å®Œæ•´
    - understanding_summary: å¯¹ç”¨æˆ·å›ç­”çš„ç†è§£æ€»ç»“
    - empathetic_response: å…±æƒ…å›åº”å†…å®¹
    - current_analysis: å½“å‰å®Œæ•´åˆ†æç»“æœ
    
    ä¼šè¯è¿½è¸ªå­—æ®µï¼š
    - debug_info: Debugåˆ†æä¿¡æ¯åˆ—è¡¨
    - session_start_time: ä¼šè¯å¼€å§‹æ—¶é—´
    - question_sequence: é—®é¢˜åºåˆ—è®°å½•
    - final_response: æœ€ç»ˆå›å¤å†…å®¹
    - assessment_duration: è¯„ä¼°æŒç»­æ—¶é—´
    
    ç”¨æˆ·ç‰¹å¾å­—æ®µï¼š
    - user_engagement_level: ç”¨æˆ·å‚ä¸åº¦ (high/medium/low)
    - response_detail_level: å›ç­”è¯¦ç»†ç¨‹åº¦ (detailed/moderate/brief)
    
    ä¸´åºŠè¯„ä¼°å­—æ®µï¼š
    - symptoms_identified: è¯†åˆ«å‡ºçš„ç—‡çŠ¶åˆ—è¡¨
    - domains_assessed: å·²è¯„ä¼°çš„é¢†åŸŸåˆ—è¡¨
    - severity_indicators: å„é¢†åŸŸä¸¥é‡ç¨‹åº¦æŒ‡æ ‡
    """
    messages: Annotated[List[AnyMessage], add_messages]
    current_question_id: Optional[str]
    user_responses: Dict[str, str]
    assessment_complete: bool
    emergency_situation: bool
    summary: str
    needs_followup: bool
    conversation_history: List[str]
    chief_complaint: str  # ç”¨æˆ·çš„ä¸»è¯‰
    
    # å¯¹è¯æ¨¡å¼ç›¸å…³å­—æ®µ
    conversation_mode: str  # å¯¹è¯æ¨¡å¼ï¼š'idle', 'interview', 'chat', 'assessment_complete'
    chat_therapist_active: bool  # CBTç–—æ„ˆå¸ˆæ˜¯å¦æ¿€æ´»
    mode_detection_result: Dict  # æ¨¡å¼æ£€æµ‹ç»“æœå’Œåˆ†æ
    conversation_turn_count: int  # ä¼šè¯è½®æ•°è®¡æ•°å™¨
    interview_mode_locked: bool  # é—®è¯Šæ¨¡å¼æ˜¯å¦å·²é”å®š
    
    # è¿½é—®ç›¸å…³å­—æ®µ
    followup_questions: List[str]  # è¿½é—®é—®é¢˜åˆ—è¡¨
    
    # é£é™©è¯„ä¼°å­—æ®µ
    risk_level: str  # é£é™©ç­‰çº§ï¼šlow/medium/high
    risk_indicators: List[str]  # é£é™©æŒ‡æ ‡åˆ—è¡¨
    
    # æƒ…æ„Ÿå’Œç†è§£åˆ†æå­—æ®µ
    emotional_state: str  # ç”¨æˆ·çš„æƒ…æ„ŸçŠ¶æ€æè¿°
    content_complete: bool  # ç”¨æˆ·å›ç­”æ˜¯å¦å®Œæ•´
    understanding_summary: str  # å¯¹ç”¨æˆ·å›ç­”çš„ç†è§£æ€»ç»“
    empathetic_response: str  # å…±æƒ…å›åº”å†…å®¹
    
    # å½“å‰åˆ†æç»“æœ
    current_analysis: Dict  # å­˜å‚¨æœ€è¿‘ä¸€æ¬¡çš„å®Œæ•´åˆ†æç»“æœ
    
    # Debugå’Œè¿½è¸ªä¿¡æ¯
    debug_info: List[Dict]  # Debugåˆ†æä¿¡æ¯åˆ—è¡¨
    session_start_time: str  # ä¼šè¯å¼€å§‹æ—¶é—´
    question_sequence: List[str]  # é—®é¢˜åºåˆ—è®°å½•
    
    # æœ€ç»ˆè¯„ä¼°ç›¸å…³
    final_response: str  # æœ€ç»ˆå›å¤å†…å®¹
    assessment_duration: int  # è¯„ä¼°æŒç»­æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
    
    # ç”¨æˆ·ç‰¹å¾æ ‡è®°
    user_engagement_level: str  # ç”¨æˆ·å‚ä¸åº¦ï¼šhigh/medium/low
    response_detail_level: str  # å›ç­”è¯¦ç»†ç¨‹åº¦ï¼šdetailed/moderate/brief
    
    # ä¸´åºŠç›¸å…³æ ‡è®°
    symptoms_identified: List[str]  # è¯†åˆ«å‡ºçš„ç—‡çŠ¶åˆ—è¡¨
    domains_assessed: List[str]  # å·²è¯„ä¼°çš„é¢†åŸŸåˆ—è¡¨
    severity_indicators: Dict[str, str]  # å„é¢†åŸŸä¸¥é‡ç¨‹åº¦æŒ‡æ ‡
    
    # è¯Šæ–­æ ‡å‡†è¿½è¸ªå­—æ®µ
    assessed_criteria: Dict[str, List[str]]  # å·²è¯„ä¼°çš„è¯Šæ–­æ ‡å‡†ï¼ŒæŒ‰éšœç¢ç±»å‹åˆ†ç»„
    criteria_results: Dict[str, bool]  # å„ä¸ªè¯Šæ–­æ ‡å‡†çš„è¯„ä¼°ç»“æœ
    current_disorder_focus: str  # å½“å‰å…³æ³¨çš„éšœç¢ç±»å‹
    
    # æ–°å¢çŠ¶æ€å­—æ®µ
    current_topic: str  # å½“å‰è¯é¢˜
    is_follow_up: bool  # æ˜¯å¦æ˜¯è¿½é—®çŠ¶æ€


# =========================
# æ ¸å¿ƒAgentç±»
# =========================

class SCID5AgentCore:
    """SCID-5é—®è¯Šä»£ç†æ ¸å¿ƒç±»"""
    
    def __init__(self, workflow_mode: str = "adaptive"):
        """
        åˆå§‹åŒ–é—®è¯Šä»£ç†
        
        Args:
            workflow_mode: å·¥ä½œæµç¨‹æ¨¡å¼
                - "adaptive": æ™ºèƒ½æ£€æµ‹æ¨¡å¼ï¼Œæ ¹æ®ç”¨æˆ·æ„å›¾è‡ªç”±åˆ‡æ¢é—®è¯Šå’Œé—²èŠ
                - "structured": å›ºå®šæµç¨‹æ¨¡å¼ï¼Œå…ˆå®Œæˆé—®è¯Šå†è½¬CBTé—²èŠ
        """
        self.workflow_mode = workflow_mode
        self.llm = self._initialize_llm()
        self.workflow = None
        self.app = None
    
    def _initialize_llm(self) -> ChatOpenAI:
        """åˆå§‹åŒ–è¯­è¨€æ¨¡å‹"""
        return ChatOpenAI(
            api_key=config.OPENAI_API_KEY,
            base_url=config.OPENAI_API_BASE,
            model=config.MODEL_NAME,
            temperature=config.TEMPERATURE,
            max_tokens=config.MAX_TOKENS
        )


# =========================
# ä¸»è¦Agentå®ç°
# =========================

class SCID5Agent(SCID5AgentCore):
    """SCID-5é—®è¯Šä»£ç†"""
    
    def __init__(self, workflow_mode: str = "adaptive"):
        """
        åˆå§‹åŒ–é—®è¯Šä»£ç†
        
        Args:
            workflow_mode: å·¥ä½œæµç¨‹æ¨¡å¼
                - "adaptive": æ™ºèƒ½æ£€æµ‹æ¨¡å¼ï¼Œæ ¹æ®ç”¨æˆ·æ„å›¾è‡ªç”±åˆ‡æ¢é—®è¯Šå’Œé—²èŠ
                - "structured": å›ºå®šæµç¨‹æ¨¡å¼ï¼Œå…ˆå®Œæˆé—®è¯Šå†è½¬CBTé—²èŠ
        """
        super().__init__(workflow_mode)
        
        # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
        from conversation_modes import ConversationModeHandler
        from interview_flow import InterviewFlowHandler  
        from response_generation import ResponseGenerator
        from emergency_handling import EmergencyHandler
        from workflow_builder import WorkflowBuilder
        
        # åˆå§‹åŒ–å„ä¸ªåŠŸèƒ½æ¨¡å—
        self.conversation_handler = ConversationModeHandler(self.llm, workflow_mode)
        self.interview_handler = InterviewFlowHandler(self.llm)
        self.response_generator = ResponseGenerator(self.llm)
        self.emergency_handler = EmergencyHandler(self.llm)
        
        # ä¸ºå“åº”ç”Ÿæˆå™¨è®¾ç½®å·¥ä½œæ¨¡å¼
        self.response_generator.workflow_mode = workflow_mode
        
        # åˆ›å»ºå·¥ä½œæµ
        self.workflow_builder = WorkflowBuilder(self)
        self.workflow = self.workflow_builder.create_workflow()
        self.app = self.workflow.compile()
    
    # ä»£ç†æ‰€æœ‰æ–¹æ³•åˆ°ç›¸åº”çš„å¤„ç†å™¨
    def start_interview(self, state: InterviewState) -> InterviewState:
        """å¼€å§‹é—®è¯Š"""
        return self.interview_handler.start_interview(state)
    
    def detect_conversation_mode(self, state: InterviewState) -> InterviewState:
        """æ£€æµ‹å¯¹è¯æ¨¡å¼"""
        return self.conversation_handler.detect_conversation_mode(state)
    
    def chat_therapist_response(self, state: InterviewState) -> InterviewState:
        """CBTç–—æ„ˆå¸ˆå“åº”"""
        return self.conversation_handler.chat_therapist_response(state)
    
    def understand_and_respond(self, state: InterviewState) -> InterviewState:
        """ç†è§£ç”¨æˆ·å›ç­”å¹¶æä¾›å…±æƒ…å›åº”"""
        return self.interview_handler.understand_and_respond(state)
    
    def ask_question(self, state: InterviewState) -> InterviewState:
        """æ™ºèƒ½æé—®"""
        return self.interview_handler.ask_question(state)
    
    def check_emergency(self, state: InterviewState) -> InterviewState:
        """æ£€æŸ¥ç´§æ€¥æƒ…å†µ"""
        return self.emergency_handler.check_emergency(state)
    
    def generate_summary(self, state: InterviewState) -> InterviewState:
        """ç”Ÿæˆè¯„ä¼°æ€»ç»“"""
        return self.response_generator.generate_summary(state)
    
    def emergency_response(self, state: InterviewState) -> InterviewState:
        """å¤„ç†ç´§æ€¥æƒ…å†µ"""
        return self.emergency_handler.emergency_response(state)
    
    # å·¥ä½œæµæ§åˆ¶æ–¹æ³•
    def should_continue_after_mode_detection(self, state: InterviewState) -> str:
        """å†³å®šæ¨¡å¼æ£€æµ‹åçš„ä¸‹ä¸€æ­¥"""
        return self.workflow_builder.should_continue_after_mode_detection(state)
    
    def should_continue_after_understand_and_respond(self, state: InterviewState) -> str:
        """ç†è§£å’Œå›åº”åçš„æµç¨‹æ§åˆ¶"""
        return self.workflow_builder.should_continue_after_understand_and_respond(state)
    
    def should_continue_after_question(self, state: InterviewState) -> str:
        """é—®é¢˜åçš„æµç¨‹æ§åˆ¶ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰"""
        return self.workflow_builder.should_continue_after_question(state)
    
    def should_continue_after_check(self, state: InterviewState) -> str:
        """æ£€æŸ¥åçš„æµç¨‹æ§åˆ¶"""
        return self.workflow_builder.should_continue_after_check(state)
    
    async def process_message(self, user_message: str, state: Optional[InterviewState] = None) -> Tuple[str, InterviewState]:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        if state is None:
            # åˆæ¬¡å¯¹è¯ï¼Œå¼€å§‹é—®è¯Šæµç¨‹
            result = await self.app.ainvoke({
                "messages": [],
                "current_question_id": None,
                "user_responses": {},
                "assessment_complete": False,
                "emergency_situation": False,
                "summary": "",
                "needs_followup": False,
                "conversation_history": [],
                "followup_questions": [],
                "risk_level": "low",
                "risk_indicators": [],
                "emotional_state": "",
                "content_complete": False,
                "understanding_summary": "",
                "empathetic_response": "",
                "current_analysis": {},
                "debug_info": [],
                "session_start_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "question_sequence": [],
                "final_response": "",
                "assessment_duration": 0,
                "user_engagement_level": "medium",
                "response_detail_level": "moderate",
                "symptoms_identified": [],
                "domains_assessed": [],
                "severity_indicators": {},
                "chief_complaint": "",
                "conversation_mode": "interview",
                "chat_therapist_active": False,
                "mode_detection_result": {},
                "current_topic": "",
                "is_follow_up": False
            })
        else:
            # ç»§ç»­å¯¹è¯ï¼Œæ·»åŠ ç”¨æˆ·æ¶ˆæ¯å¹¶å¤„ç†
            user_msg = HumanMessage(content=user_message)
            updated_state = {
                **state,
                "messages": state["messages"] + [user_msg]
            }
            
            # å…ˆç†è§£å’Œå›åº”ç”¨æˆ·çš„è¯
            analyzed_state = self.understand_and_respond(updated_state)
            
            # ç„¶åç»§ç»­å·¥ä½œæµ
            result = await self.app.ainvoke(analyzed_state)
        
        # è·å–æœ€åä¸€æ¡AIæ¶ˆæ¯
        ai_response = ""
        if result["messages"]:
            for msg in reversed(result["messages"]):
                if isinstance(msg, (AIMessage, SystemMessage)):
                    ai_response = msg.content if hasattr(msg, 'content') else str(msg)
                    break
        
        return ai_response, result

    def process_message_sync(self, user_message: str, state: Optional[dict] = None) -> Tuple[str, dict]:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ - åŒæ­¥ç‰ˆæœ¬ï¼Œä½¿ç”¨æ–°çš„å·¥ä½œæµç¨‹"""
        try:
            # å¦‚æœæ˜¯å¼€å§‹è¯„ä¼°æˆ–è€…æ²¡æœ‰çŠ¶æ€ï¼Œä½¿ç”¨å·¥ä½œæµåˆå§‹åŒ–
            if user_message == "å¼€å§‹è¯„ä¼°" or state is None:
                # åˆ›å»ºåˆå§‹çŠ¶æ€ï¼Œä½¿ç”¨start_interviewæ–¹æ³•
                initial_state = self.start_interview({
                    "messages": [],
                    "current_question_id": None,
                    "user_responses": {},
                    "assessment_complete": False,
                    "emergency_situation": False,
                    "summary": "",
                    "needs_followup": False,
                    "conversation_history": [],
                    "chief_complaint": "",
                    "conversation_mode": "idle",
                    "chat_therapist_active": False,
                    "mode_detection_result": {},
                    "conversation_turn_count": 0,
                    "interview_mode_locked": False,
                    "followup_questions": [],
                    "risk_level": "low",
                    "risk_indicators": [],
                    "emotional_state": "",
                    "content_complete": False,
                    "understanding_summary": "",
                    "empathetic_response": "",
                    "current_analysis": {},
                    "debug_info": [],
                    "session_start_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "question_sequence": [],
                    "final_response": "",
                    "assessment_duration": 0,
                    "user_engagement_level": "medium",
                    "response_detail_level": "moderate",
                    "symptoms_identified": [],
                    "domains_assessed": [],
                    "severity_indicators": {},
                    "current_topic": "",
                    "is_follow_up": False
                })
                
                # ä»messagesä¸­è·å–AIçš„è‡ªæˆ‘ä»‹ç»å›å¤
                ai_response = ""
                if initial_state["messages"]:
                    for msg in reversed(initial_state["messages"]):
                        if isinstance(msg, AIMessage):
                            ai_response = msg.content if hasattr(msg, 'content') else str(msg)
                            break
                
                return ai_response, initial_state
            
            # å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œä½¿ç”¨æ–°çš„å·¥ä½œæµç¨‹
            if state:
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°çŠ¶æ€
                current_state = state.copy()
                current_state["messages"] = current_state.get("messages", []) + [HumanMessage(content=user_message)]
                
                # æ­¥éª¤1: æ£€æµ‹å¯¹è¯æ¨¡å¼
                mode_state = self.detect_conversation_mode(current_state)
                
                # æ ¹æ®æ£€æµ‹åˆ°çš„æ¨¡å¼é€‰æ‹©å¤„ç†è·¯å¾„
                mode = mode_state.get("conversation_mode", "interview")
                
                if mode == "chat" or mode == "supportive_chat" or mode == "assessment_complete":
                    # ä½¿ç”¨CBTç–—æ„ˆå¸ˆå›åº”
                    print(f"ğŸ¯ è¿›å…¥CBTç–—æ„ˆå¸ˆæ¨¡å¼ï¼Œæ£€æµ‹æ¨¡å¼: {mode}", flush=True)
                    result_state = self.chat_therapist_response(mode_state)
                    ai_response = result_state.get("final_response", "æˆ‘å¾ˆé«˜å…´å’Œæ‚¨èŠå¤©ï¼Œæœ‰ä»€ä¹ˆæƒ³èŠçš„å—ï¼Ÿ")
                    return ai_response, result_state
                
                elif mode == "interview" or mode == "continue_interview":
                    # ä½¿ç”¨é—®è¯Šæµç¨‹
                    # ç†è§£å’Œå›åº”ç”¨æˆ·è¾“å…¥ï¼ˆå·²åŒ…å«ä¸‹ä¸€ä¸ªé—®é¢˜çš„ç”Ÿæˆï¼‰
                    understood_state = self.understand_and_respond(mode_state)
                    
                    # ä»messagesä¸­è·å–å›åº”
                    ai_response = ""
                    if understood_state["messages"]:
                        for msg in reversed(understood_state["messages"]):
                            if isinstance(msg, AIMessage):
                                ai_response = msg.content
                                break
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†
                    if understood_state.get("emergency_situation", False):
                        # å¤„ç†ç´§æ€¥æƒ…å†µ
                        emergency_state = self.emergency_response(understood_state)
                        # ä»messagesä¸­è·å–ç´§æ€¥å“åº”
                        emergency_response = ""
                        if emergency_state["messages"]:
                            for msg in reversed(emergency_state["messages"]):
                                if isinstance(msg, AIMessage):
                                    emergency_response = msg.content
                                    break
                        return emergency_response, emergency_state
                    
                    elif understood_state.get("assessment_complete", False):
                        # ç”Ÿæˆæ€»ç»“
                        summary_state = self.generate_summary(understood_state)
                        # ä»messagesä¸­è·å–æ€»ç»“
                        summary_response = ""
                        if summary_state["messages"]:
                            for msg in reversed(summary_state["messages"]):
                                if isinstance(msg, AIMessage):
                                    summary_response = msg.content
                                    break
                        return summary_response, summary_state
                    
                    else:
                        # è¿”å›ç†è§£å’Œå›åº”çš„ç»“æœï¼ˆå·²åŒ…å«ä¸‹ä¸€ä¸ªé—®é¢˜ï¼‰
                        return ai_response, understood_state
                
                else:
                    # é»˜è®¤ä½¿ç”¨é—®è¯Šæ¨¡å¼
                    return self.response_generator.fallback_response(current_state, user_message)
            
            return "è¯·é‡æ–°å¼€å§‹è¯„ä¼°ã€‚", {}
            
        except Exception as e:
            error_msg = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}"
            print(f"DEBUG: process_message_sync error: {e}", flush=True)
            import traceback
            traceback.print_exc()
            return error_msg, state or {}
    
    def _get_next_question_response(self, current_question_id: str, user_response: str, state: dict) -> str:
        """æ ¹æ®å½“å‰é—®é¢˜å’Œç”¨æˆ·å›ç­”ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜"""
        return self.response_generator.get_next_question_response(current_question_id, user_response, state)


# =========================
# å·¥å‚å‡½æ•°
# =========================

def create_agent(workflow_mode: str = "adaptive") -> SCID5Agent:
    """
    åˆ›å»ºSCID5ä»£ç†å®ä¾‹
    
    Args:
        workflow_mode: å·¥ä½œæµç¨‹æ¨¡å¼
            - "adaptive": æ™ºèƒ½æ£€æµ‹æ¨¡å¼ï¼Œæ ¹æ®ç”¨æˆ·æ„å›¾è‡ªç”±åˆ‡æ¢é—®è¯Šå’Œé—²èŠ
            - "structured": å›ºå®šæµç¨‹æ¨¡å¼ï¼Œå…ˆå®Œæˆé—®è¯Šå†è½¬CBTé—²èŠ
    
    Returns:
        SCID5Agent: é…ç½®å¥½çš„ä»£ç†å®ä¾‹
    """
    return SCID5Agent(workflow_mode=workflow_mode)


# å…¨å±€ä»£ç†å®ä¾‹
# å¯ä»¥é€šè¿‡ä¿®æ”¹è¿™é‡Œçš„workflow_modeå‚æ•°æ¥åˆ‡æ¢å·¥ä½œæ¨¡å¼ï¼š
# - "adaptive": æ™ºèƒ½æ£€æµ‹æ¨¡å¼ï¼Œæ ¹æ®ç”¨æˆ·æ„å›¾è‡ªç”±åˆ‡æ¢é—®è¯Šå’Œé—²èŠ
# - "structured": å›ºå®šæµç¨‹æ¨¡å¼ï¼Œå…ˆå®Œæˆé—®è¯Šå†è½¬CBTé—²èŠ

# å»¶è¿Ÿåˆå§‹åŒ–å…¨å±€å®ä¾‹ä»¥é¿å…å¾ªç¯å¯¼å…¥
_global_agent = None

def get_scid5_agent(workflow_mode: str = "adaptive") -> SCID5Agent:
    """è·å–å…¨å±€SCID5ä»£ç†å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
    global _global_agent
    if _global_agent is None:
        _global_agent = SCID5Agent(workflow_mode=workflow_mode)
    return _global_agent

# ä¸ºäº†å‘åå…¼å®¹ï¼Œå¯ä»¥è¿™æ ·ä½¿ç”¨ï¼š
# scid5_agent = get_scid5_agent()